<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Optimization algorithm and options &#8212; grampc 2.3 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="_static/classic.css?v=def86cc0" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    
    <script src="_static/documentation_options.js?v=57236720"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script>window.MathJax = {"tex": {"macros": {"mb": ["\\boldsymbol{#1}", 1]}}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Usage of GRAMPC" href="usage.html" />
    <link rel="prev" title="Problem formulation and implementation" href="problem_formulation.html" /> 
  </head><body>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="prf-prf.html" title="Proof Index"
             >Proof</a> |</li>
        <li class="right" >
          <a href="usage.html" title="Usage of GRAMPC"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="problem_formulation.html" title="Problem formulation and implementation"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">grampc 2.3 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Optimization algorithm and options</a></li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <section id="optimization-algorithm-and-options">
<span id="chap-algopt"></span><h1>Optimization algorithm and options<a class="headerlink" href="#optimization-algorithm-and-options" title="Link to this heading">¶</a></h1>
<p>This chapter summarizes the optimization scheme that is used to solve
the optimization problem in <a class="reference internal" href="problem_formulation.html#chap-problemformulation"><span class="std std-ref">Problem formulation and implementation</span></a>. This includes
the basic algorithm as well as the options that can be adjusted by the
user. Note that all options as well as their corresponding default
values are listed in Table <a class="reference internal" href="appendix.html#tab-listofoptions"><span class="std std-ref">Algorithmic Options.</span></a>. The setting of
the options is detailed in <a class="reference internal" href="usage.html#chap-grampcstructure"><span class="std std-ref">Usage of GRAMPC</span></a> for
usage in C and Matlab.</p>
<section id="optimization-algorithm">
<span id="sec-algopt-basicalgorithm"></span><h2>Optimization algorithm<a class="headerlink" href="#optimization-algorithm" title="Link to this heading">¶</a></h2>
<p>The optimization algorithm of GRAMPC is based on an augmented
Lagrangian formulation with an inner projected gradient method as
minimization step and an outer multiplier and penalty update. This
section gives a brief sketch of the algorithm. Note that a more detailed
description is given in <a class="footnote-reference brackets" href="#footcite-englert-oe-2019" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p>
<section id="augmented-lagrangian-method">
<span id="sec-algopt-auglag"></span><h3>Augmented Lagrangian method<a class="headerlink" href="#augmented-lagrangian-method" title="Link to this heading">¶</a></h3>
<p>GRAMPC implements the augmented Lagrangian approach to handle the equality and inequality constraints of the OCP.
The constraints are adjoined to the integral cost function using the time-dependent multipliers
<span class="math notranslate nohighlight">\(\mb{\mu}= [\mb{\mu}_{\mb{g}}^\mathsf{T}, \mb{\mu}_{\mb{h}}^\mathsf{T}]^\mathsf{T}\)</span>
and penalties <span class="math notranslate nohighlight">\(\mb{c}= [\mb{c}_{\mb{g}}^\mathsf{T},\mb{c}_{\mb{h}}^\mathsf{T}]^\mathsf{T}\)</span>.
Similarly, multipliers
<span class="math notranslate nohighlight">\(\mb{\mu}_T = [\mb{\mu}_{\mb{g}_T}^\mathsf{T}, \mb{\mu}_{\mb{h}_T}^\mathsf{T}]^\mathsf{T}\)</span>
and penalties
<span class="math notranslate nohighlight">\(\mb{c}_T = [\mb{c}_{\mb{g}_T}^\mathsf{T}, \mb{c}_{\mb{h}_T}^\mathsf{T}]^\mathsf{T}\)</span>
are used for the terminal constraints.
Where appropriate, the syntax
<span class="math notranslate nohighlight">\(\mb{\bar \mu} = (\mb{\mu}_{\mb{g}}, \mb{\mu}_{\mb{h}}, \mb{\mu}_{\mb{g}_T}, \mb{\mu}_{\mb{h}_T})\)</span>
and
<span class="math notranslate nohighlight">\(\mb{\bar c} = (\mb{c}_{\mb{g}}, \mb{c}_{\mb{h}}, \mb{c}_{\mb{g}_T}, \mb{c}_{\mb{h}_T})\)</span>
is used to denote all multipliers and penalties.
The algorithm requires a reformulation of the inequality constraints that leads to the transformed functions (see <a class="footnote-reference brackets" href="#footcite-englert-oe-2019" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> for details)</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mb{\bar h}(\mb{x}, \mb{u}, \mb{p}, t, \mb{\mu}_{\mb{h}}, \mb{c}_{\mb{h}}) &amp;=
\mb{\max}\left\{ \mb{h}(\mb{x}, \mb{u}, \mb{p}, t), -\mb{C}_{\mb{h}}^{-1} \mb{\mu}_{\mb{h}} \right\}
\\
\mb{\bar h}_T(\mb{x}, \mb{p}, T, \mb{\mu}_{\mb{h}_T}, \mb{c}_{\mb{h}_T}) &amp;=
\mb{\max}\left\{ \mb{h}_T(\mb{x}, \mb{p}, T), -\mb{C}_{\mb{h}_T}^{-1} \mb{\mu}_{\mb{h}_T} \right\}\end{split}\]</div>
<p>with the component-wise <strong>max</strong>-function and the diagonal matrix syntax <span class="math notranslate nohighlight">\(\mb{C}= {\rm diag}(\mb{c})\)</span>.
The augmented Lagrangian function is defined as</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-auglag">
<span class="eqno">(3)<a class="headerlink" href="#equation-eq-algopt-auglag" title="Link to this equation">¶</a></span>\[\bar J(\mb{u}, \mb{p}, T, \mb{\bar \mu}, \mb{\bar c};\mb{x}_0) =
\bar V(\mb{x}, \mb{p}, T, \mb{\mu}_T, \mb{c}_T)
+ \int_0^T \bar l(\mb{x}, \mb{u}, \mb{p}, t, \mb{\mu}, \mb{c}) \, \mathrm dt\]</div>
<p>with the augmented terminal cost term</p>
<div class="math notranslate nohighlight">
\[\begin{split}\bar V(\mb{x}, \mb{p}, T, \mb{\mu}_T, \mb{c}_T) =\,&amp; V(\mb{x}, \mb{p}, T)
+ \mb{\mu}_{\mb{g}_T}^\mathsf{T}\, \mb{g}_T(\mb{x}, \mb{p}, T)
+ \frac12 \| \mb{g}_T(\mb{x}, \mb{p}, T) \|^2_{\mb{C}_{\mb{g}_T}}
\nonumber\\
&amp;+ \mb{\mu}_{\mb{h}_T}^\mathsf{T}\, \mb{\bar h}_T(\mb{x}, \mb{p}, T, \mb{\mu}_{\mb{h}_T},\mb{c}_{\mb{h}_T})
+ \frac12 \| \mb{\bar h}_T(\mb{x}, \mb{p}, T, \mb{\mu}_{\mb{h}_T},\mb{c}_{\mb{h}_T}) \|^2_{\mb{C}_{\mb{h}_T}}\end{split}\]</div>
<p>and the augmented integral cost term</p>
<div class="math notranslate nohighlight">
\[\begin{split}\bar l(\mb{x}, \mb{u}, \mb{p}, t, \mb{\mu}, \mb{c}) =\,&amp; l(\mb{x}, \mb{u}, \mb{p}, t)
+ \mb{\mu}_{\mb{g}}^\mathsf{T}\, \mb{g}(\mb{x}, \mb{u}, \mb{p}, t)
+ \frac12 \| \mb{g}(\mb{x}, \mb{u}, \mb{p}, t) \|^2_{\mb{C}_{\mb{g}}}
\nonumber\\
&amp;+ \mb{\mu}_{\mb{h}}^\mathsf{T}\, \mb{\bar h}(\mb{x}, \mb{u}, \mb{p}, t, \mb{\mu_h},\mb{c_h})
+ \frac12 \| \mb{\bar h}(\mb{x}, \mb{u}, \mb{p}, t, \mb{\mu_h},\mb{c_h}) \|^2_{\mb{C}_{\mb{h}}} \,.\end{split}\]</div>
<p>Instead of solving the original problem, the algorithm solves the max-min-problem</p>
<div class="math notranslate nohighlight" id="equation-eq-maxmin">
<span class="eqno">(4)<a class="headerlink" href="#equation-eq-maxmin" title="Link to this equation">¶</a></span>\[\begin{split}\max_{\mb{\bar\mu}} \, \min_{\mb{u}, \mb{p}, T} \quad&amp;
\bar{ J}(\mb{u}, \mb{p}, T, \mb{\bar\mu}, \mb{\bar c}; \mb{x}_0)
\\
\textrm{s.t.} \quad&amp; \mb{M} \mb{\dot x}(t) = \mb{f}(\mb{x}, \mb{u}, \mb{p}, t)
\,,\quad
\mb{x}(0) = \mb{x}_0
\\
&amp; \mb{u}(t) \in [\mb{u}_{\min}, \mb{u}_{\max}] %\,,\quad t \in [0, T]
\,,\quad
t\in[0,T]
\\
&amp; \mb{p} \in [\mb{p}_{\min}, \mb{p}_{\max}]
\,,\quad
T \in [T_{\min}, T_{\max}] \,,\end{split}\]</div>
<p>whereby the augmented Lagrangian function <span class="math notranslate nohighlight">\(\bar{J}\)</span> is maximized with respect to the multipliers <span class="math notranslate nohighlight">\(\mb{\bar \mu}\)</span> and minimized with respect to the controls <span class="math notranslate nohighlight">\(\mb{u}\)</span>, the parameters <span class="math notranslate nohighlight">\(\mb{p}\)</span> and the end time <span class="math notranslate nohighlight">\(\mb{T}\)</span>.
Note that the full set of optimization variables <span class="math notranslate nohighlight">\((\mb{u},\mb{p},T)\)</span> is considered in what follows for the sake of completeness.
The max-min-problem <a class="reference internal" href="#equation-eq-maxmin">(4)</a> corresponds to the dual problem of <a class="reference internal" href="problem_formulation.html#equation-ocp">(1)</a> in the case of <span class="math notranslate nohighlight">\(\mb{\bar c} = \mb{0}\)</span>.
The maximization step is performed by steepest ascent using the constraint residual as direction and the penalty parameter as step size.
See <a class="footnote-reference brackets" href="#footcite-englert-oe-2019" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a> a detailed description of the augmented Lagrangian algorithm.</p>
</section>
<section id="projected-gradient-method">
<span id="sec-algopt-projgrad"></span><h3>Projected gradient method<a class="headerlink" href="#projected-gradient-method" title="Link to this heading">¶</a></h3>
<p>GRAMPC uses a projected gradient method to solve the inner
minimization problem subject to the dynamics
<span class="math notranslate nohighlight">\(\mb{f}(\mb{x}(t), \mb{u}(t), \mb{p}, t)\)</span> as well as the box constraints
<span class="math notranslate nohighlight">\(\mb{u}(t) \in \left[\mb{u}_{\min}, \mb{u}_{\max}\right]\)</span> and
<span class="math notranslate nohighlight">\(\mb{p} \in \left[\mb{p}_{\min}, \mb{p}_{\max}\right]\)</span>.
The algorithm is based on the first-order optimality conditions that can be compactly stated using the Hamiltonian</p>
<div class="math notranslate nohighlight">
\[H(\mb{x}, \mb{u}, \mb{p}, \mb{\lambda}, t, \mb{\mu}, \mb{c}) =
\bar{ l}(\mb{x}, \mb{u}, \mb{p}, t, \mb{\mu}, \mb{c}) + \mb{\lambda}^\mathsf{T}\mb{f}(\mb{x}, \mb{u}, \mb{p}, t)\]</div>
<p>with the adjoint states <span class="math notranslate nohighlight">\(\mb{\lambda}\)</span>.
The canonical equations are then given by</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-optcondlambda">
<span class="eqno">(5)<a class="headerlink" href="#equation-eq-algopt-optcondlambda" title="Link to this equation">¶</a></span>\[ \begin{align}\begin{aligned}\mb{M}\mb{\dot x} &amp;= \mb{f} (\mb{x}, \mb{u}, \mb{p}, t) \,, &amp;\mb{x}(0) &amp;= \mb{x}_0 \,,\\\mb{M}^\mathsf{T}\mb{\dot \lambda} &amp;= -H_{\mb{x}}(\mb{x}, \mb{u}, \mb{p}, \mb{\lambda}, t, \mb{\mu}, \mb{c}) \,, &amp;\mb{M}^\mathsf{T}\mb{\lambda}(T) &amp;= \bar{ V}_{\mb{x}}(\mb{x}(T), \mb{p}, T, \mb{\mu}_T, \mb{c}_T)\end{aligned}\end{align} \]</div>
<p>consisting of the original dynamics <span class="math notranslate nohighlight">\(\dot{x}\)</span> and the adjoint dynamics <span class="math notranslate nohighlight">\(\dot{\lambda}\)</span>.
The canonical equations can be iteratively solved in forward and backward time for given initial values of the optimization variables.
In each iteration and depending on the optimization variables of the actual problem to be solved, the gradients</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mb{d}_{\mb{u}} &amp;= H_{\mb{u}}(\mb{x}, \mb{u}, \mb{p}, \mb{\lambda}, t, \mb{\mu}, \mb{c})
\\
\mb{d}_{\mb{p}} &amp;= \bar V_{\mb{p}}(\mb{x}(T), \mb{p}, T, \mb{\mu}_T, \mb{c}_T) +     \int_0^T H_{\mb{p}}(\mb{x}, \mb{u}, \mb{p}, \mb{\lambda}, t, \mb{\mu}, \mb{c}) \, {\rm d}t
\\
d_T &amp;= \bar V_T(\mb{x}(T), \mb{p}, T, \mb{\mu}_T, \mb{c}_T) + H(\mb{x}(T), \mb{u}(T), \mb{p}, \mb{\lambda}(T), T, \mb{\mu}(T), \mb{c}(T))\end{split}\]</div>
<p>with respect to the controls <span class="math notranslate nohighlight">\(\mb{u}\)</span>, parameters <span class="math notranslate nohighlight">\(\mb{p}\)</span>,
and end time <span class="math notranslate nohighlight">\(T\)</span> are used to formulate a line search problem</p>
<div class="math notranslate nohighlight">
\[\min_{\alpha} \bar{J} \left(
  \mb{\psi}_{\mb{u}} \left( \mb{u} - \alpha \mb{d}_{\mb{u}} \right),
  \mb{\psi}_{\mb{p}} \left( \mb{p} - \gamma_{\mb{p}} \alpha \mb{d}_{\mb{p}} \right),
  \psi_{T} \left( T - \gamma_{T} \alpha d_{T} \right);
  \mb{\bar \mu}, \mb{\bar c}, \mb{x}_0
\right)\]</div>
<p>with projection functions <span class="math notranslate nohighlight">\(\mb{\psi}_{\mb{u}}\)</span>,
<span class="math notranslate nohighlight">\(\mb{\psi}_{\mb{p}}\)</span> and <span class="math notranslate nohighlight">\(\psi_{T}\)</span> and,
finally, to update the optimization variables according to</p>
<div class="math notranslate nohighlight">
\[\mb{u} \leftarrow \mb{\psi}_{\mb{u}} \left( \mb{u} - \alpha \mb{d}_{\mb{u}} \right)
\,,\quad
\mb{p} \leftarrow \mb{\psi}_{\mb{p}} \left( \mb{p} - \gamma_{\mb{p}} \alpha \mb{d}_{\mb{p}} \right)
\,,\quad
T \leftarrow \psi_{T} \left( T - \gamma_{T} \alpha d_{T} \right) \,.\]</div>
<p>See <a class="footnote-reference brackets" href="#footcite-intech-graichenkaepernick2012" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-kaepernick2014" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-englert-oe-2019" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>
for a detailed description of the projected gradient algorithm.
GRAMPC provides two methods for the approximate solution of the line search
problem, which are explained in <a class="reference internal" href="#sec-algopt-linesearch"><span class="std std-ref">Line search</span></a>.</p>
</section>
<section id="algorithmic-structure">
<span id="sec-algopt-structure"></span><h3>Algorithmic structure<a class="headerlink" href="#algorithmic-structure" title="Link to this heading">¶</a></h3>
<div class="proof algorithm admonition" id="alg:AlgOpt:GrampcAlgorithm">
<p class="admonition-title"><span class="caption-number">Algorithm 1 </span> (Basic algorithmic structure of GRAMPC.)</p>
<section class="algorithm-content" id="proof-content">
<p>Optional: Shift trajectories by sampling time <span class="math notranslate nohighlight">\(\Delta t\)</span></p>
<dl>
<dt><strong>For</strong> <span class="math notranslate nohighlight">\(i = 1\)</span> to <span class="math notranslate nohighlight">\(i_{max}\)</span> <strong>do</strong></dt><dd><dl>
<dt><strong>For</strong> <span class="math notranslate nohighlight">\(j = 1\)</span> to <span class="math notranslate nohighlight">\(j_{max}\)</span> <strong>do</strong></dt><dd><dl>
<dt><strong>If</strong> <span class="math notranslate nohighlight">\(i &gt; 1\)</span> and <span class="math notranslate nohighlight">\(j = 1\)</span> <strong>then</strong></dt><dd><p>Set <span class="math notranslate nohighlight">\(\mb x^{i|j} =\mb x^{i-1}\)</span></p>
</dd>
<dt><strong>else</strong></dt><dd><p>Compute <span class="math notranslate nohighlight">\(\mb x^{i|j}\)</span> by forward time integration of system dynamics</p>
<p>Evalute all constraints</p>
</dd>
</dl>
<p><strong>End If</strong>
Compute <span class="math notranslate nohighlight">\(\mb \lambda^{i|j}\)</span> by backward time integration of adjoint system</p>
<p>Evaluate gradients <span class="math notranslate nohighlight">\(\mb{d_u}^{i|j}\)</span>, <span class="math notranslate nohighlight">\(\mb{d_p}^{i|j}\)</span> and <span class="math notranslate nohighlight">\(d_T^{i|j}\)</span></p>
<p>Solve line search problem to determine step size <span class="math notranslate nohighlight">\(\alpha^{i|j}\)</span></p>
</dd>
</dl>
</dd>
</dl>
</section>
</div><p>The basic structure of the algorithm that is implemented in the main calling function <code class="docutils literal notranslate"><span class="pre">grampc_run</span></code> is outlined in
<a class="reference internal" href="#alg:AlgOpt:GrampcAlgorithm">Algorithm 1</a>.
The projected gradient method is realized in the inner loop and consists
of the forward and backward integration of the canonical equations as
well as the update of the optimization variables based on the gradient
and the approximate solution of the line search problem. The outer loop
corresponds to the augmented Lagrangian method consisting of the
solution of the inner minimization problem and the update of the
multipliers and penalty parameters.</p>
<p>As an alternative to the augmented Lagrangian framework, the user can
choose external penalty functions in GRAMPC that handle the equality
and inequality constraints as “soft” constraints. In this case, the
multipliers <span class="math notranslate nohighlight">\(\mb{\bar \mu}\)</span> are fixed at zero and only the
penalty parameters are updated in the outer loop. Note that the user can
set the options <code class="docutils literal notranslate"><span class="pre">PenaltyIncreaseFactor</span></code> and <code class="docutils literal notranslate"><span class="pre">PenaltyDecreaseFactor</span></code> to <span class="math notranslate nohighlight">\(1.0\)</span> in order to keep the penalty
parameters at the initial value <code class="docutils literal notranslate"><span class="pre">PenaltyMin</span></code>. The single steps of the algorithm and
the related options are described in more detail in the following sections.</p>
<p>The following options can be used to adjust the basic algorithm. The
corresponding default values are listed in
<a class="reference internal" href="appendix.html#tab-listofoptions"><span class="std std-numref">Table 4</span></a> in the appendix.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MaxMultIter</span></code>: Sets the maximum number of augmented Lagrangian iterations
<span class="math notranslate nohighlight">\(i_\text{max} \geq 1\)</span>. If the option <code class="docutils literal notranslate"><span class="pre">ConvergenceCheck</span></code> is activated, the
algorithm evaluates the convergence criterion and terminates if the
inner minimization converged and all constraints are satisfied within
the tolerance defined by <code class="docutils literal notranslate"><span class="pre">ConstraintsAbsTol</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MaxGradIter</span></code>: If the option <code class="docutils literal notranslate"><span class="pre">ConvergenceCheck</span></code> is activated, the algorithm terminates the inner loop
as soon as the convergence criterion is fulfilled.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EqualityConstraints</span></code>: Equality constraints
<span class="math notranslate nohighlight">\(\mb{g}(\mb{x}(t), \mb{u}(t), \mb{p}, t) = \mb{0}\)</span>
can be disabled by the option value <code class="docutils literal notranslate"><span class="pre">off</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">InequalityConstraints</span></code>: To disable inequality constraints
<span class="math notranslate nohighlight">\(\mb{h}(\mb{x}(t), \mb{u}(t), \mb{p}, t) \le \mb{0}\)</span>,
set this option to <code class="docutils literal notranslate"><span class="pre">off</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TerminalEqualityConstraints</span></code>: To disable terminal equality constraints
<span class="math notranslate nohighlight">\(\mb{g}_T(\mb{x}(T), \mb{p}, T) = \mb{0}\)</span>,
set this option to <code class="docutils literal notranslate"><span class="pre">off</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TerminalInequalityConstraints</span></code>: To disable terminal inequality constraints
<span class="math notranslate nohighlight">\(\mb{h}_T(\mb{x}(T), \mb{p}, T) \le \mb{0}\)</span>,
set this option to <code class="docutils literal notranslate"><span class="pre">off</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ConstraintsHandling</span></code>: State constraints are handled either by means of the augmented
Lagrangian approach (option value <code class="docutils literal notranslate"><span class="pre">auglag</span></code>) or as soft constraints by outer
penalty functions (option value <code class="docutils literal notranslate"><span class="pre">extpen</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OptimControl</span></code>: Specifies whether the cost functional should be minimized with
respect to the control variable <span class="math notranslate nohighlight">\(\mb{u}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OptimParam</span></code>: Specifies whether the cost functional should be minimized with
respect to the optimization parameters <span class="math notranslate nohighlight">\(\mb{p}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OptimTime</span></code>: Specifies whether the cost functional should be minimized with
respect the horizon length <span class="math notranslate nohighlight">\(T\)</span> (free end time problem) or if
<span class="math notranslate nohighlight">\(T\)</span> is kept constant.</p></li>
</ul>
</section>
</section>
<section id="numerical-integration">
<span id="sec-algopt-integration"></span><h2>Numerical Integration<a class="headerlink" href="#numerical-integration" title="Link to this heading">¶</a></h2>
<p>GRAMPC employs a continuous-time formulation of the optimization
problem. However, internally, all time-dependent functions are stored in
discretized form with <span class="math notranslate nohighlight">\(N_\text{hor}\)</span> elements and numerical
integration is performed to compute the cost functional and to solve the
differential equations.</p>
<section id="integration-of-cost-functional-and-explicit-odes">
<span id="sec-algopt-integrationcostode"></span><h3>Integration of cost functional and explicit ODEs<a class="headerlink" href="#integration-of-cost-functional-and-explicit-odes" title="Link to this heading">¶</a></h3>
<p>The approximate line search method requires the evaluation of the cost
functional. To this end, the integral cost is integrated numerically
with the trapezodial, Simpson rule or discrete summation and the
terminal cost is added. Note that the discrete summation does not
compute the Riemann sum but the plain sum with
<span class="math notranslate nohighlight">\(\sum_k l(\mb{x}_k, \mb{u}_k, \mb{p}, t_k)\)</span>.
The cost values are additionally evaluated at the end of the
optimization as an add-on information for the user.</p>
<p>The gradient algorithm involves the sequential forward integration of
the system dynamics and backward integration of the adjoint dynamics.
GRAMPC implements three integrators with fixed step size (Euler,
modified Euler and Heun) and time-discrete dynamics. Furthermore, a
4th-order Runge-Kutta m ethod and a semi-implicit Rosenbrock solver
(RODAS <a class="footnote-reference brackets" href="#footcite-hairer-book-1996-stiff" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-rodas-webpage-2018" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a>)
with variable step size are available.</p>
<p>Evaluating the trajectories via time-discrete dynamics requires that the
prediction horizon <code class="docutils literal notranslate"><span class="pre">Thor</span></code> matches the discretization steps <code class="docutils literal notranslate"><span class="pre">Nhor</span></code> and sample time <code class="docutils literal notranslate"><span class="pre">dt</span></code> and  via</p>
<div class="math notranslate nohighlight">
\[\mathtt{Thor} = (\mathtt{Nhor} - 1) \cdot \mathtt{dt}.\]</div>
<p>The following options can be used to adjust the numerical integrations:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Nhor</span></code>: Number of discretization points within the time interval <span class="math notranslate nohighlight">\([0,T]\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IntegralCost</span></code>, <code class="docutils literal notranslate"><span class="pre">TerminalCost</span></code>: Indicate if the integral and/or terminal cost functions are defined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IntegratorCost</span></code>: This option specifies the integration scheme for the cost
functionals. Possible values are <code class="docutils literal notranslate"><span class="pre">trapezodial</span></code>, <code class="docutils literal notranslate"><span class="pre">simpson</span></code> and <code class="docutils literal notranslate"><span class="pre">discrete</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Integrator</span></code>: This option specifies the integration scheme for the system and
adjoint dynamics. Possible values are <code class="docutils literal notranslate"><span class="pre">euler</span></code>, <code class="docutils literal notranslate"><span class="pre">modeuler</span></code>,
<code class="docutils literal notranslate"><span class="pre">heun</span></code> and <code class="docutils literal notranslate"><span class="pre">discrete</span></code> with fixed step size and <code class="docutils literal notranslate"><span class="pre">ruku45</span></code> and
<code class="docutils literal notranslate"><span class="pre">rodas</span></code> with variable step size.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IntegratorMinStepSize</span></code>: Minimum step size for RODAS and the Runge-Kutta integrator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IntegratorMaxSteps</span></code>: Maximum number of steps for RODAS and the Runge-Kutta integrator.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IntegratorRelTol</span></code>: Relative tolerance for RODAS and the Runge-Kutta integrator with
variable step size. Note that this option may be insignificant if the
minimum step size is chosen too high or the maximum number of steps
is set too low.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IntegratorAbsTol</span></code>: Absolute tolerance for RODAS and the Runge-Kutta integrator with
variable step size. Note that this option may be insignificant if the
minimum step size is chosen too high or the maximum number of steps
is set too low.</p></li>
</ul>
</section>
<section id="integration-of-semi-implicit-odes-and-daes-rodas">
<span id="sec-algopt-integrationrodas"></span><h3>Integration of semi-implicit ODEs and DAEs (RODAS)<a class="headerlink" href="#integration-of-semi-implicit-odes-and-daes-rodas" title="Link to this heading">¶</a></h3>
<p>GRAMPC supports problem descriptions with ordinary differential
equations in semi-implicit form as well as differential algebraic
equations using the solver RODAS for numerical integration (see
<a class="reference internal" href="problem_formulation.html#sec-problemimplementation-implicit"><span class="std std-ref">Problems involving semi-implicit ODEs and DAEs</span></a>). If a
semi-implicit problem or differential algebraic equations are
considered, the mass matrix <span class="math notranslate nohighlight">\(\mb{M}\)</span> and its transposed
version <span class="math notranslate nohighlight">\(\mb{M}^\mathsf{T}\)</span> must be defined by the C
functions <code class="docutils literal notranslate"><span class="pre">Mfct</span></code> and <code class="docutils literal notranslate"><span class="pre">Mtrans</span></code>. The numerical integration can be accelerated by
additionally providing the C functions <code class="docutils literal notranslate"><span class="pre">dfdx</span></code>, <code class="docutils literal notranslate"><span class="pre">dfdxtrans</span></code>, <code class="docutils literal notranslate"><span class="pre">dfdt</span></code> and <code class="docutils literal notranslate"><span class="pre">dHdxdt</span></code>. See
<a class="reference internal" href="problem_formulation.html#sec-problemimplementation"><span class="std std-ref">Problem implementation</span></a> for a detailed description of the problem implementation.</p>
<p>The integration with RODAS is configured by a number of flags that are
passed to the solver using the vector <code class="docutils literal notranslate"><span class="pre">FlagsRodas</span></code> with the elements
<code class="docutils literal notranslate"><span class="pre">[IFCN,</span> <span class="pre">IDFX,</span> <span class="pre">IJAC,</span> <span class="pre">IMAS,</span> <span class="pre">MLJAC,</span> <span class="pre">MUJAC,</span> <span class="pre">MLMAS,</span> <span class="pre">MUMAS]</span></code>.
See <a class="footnote-reference brackets" href="#footcite-rodas-webpage-2018" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-hairer-book-1996-stiff" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a> for a
detailed description of these flags. The default values
<span class="math notranslate nohighlight">\([0,0,0,0,N_x,N_x,N_x,N_x]\)</span> correspond to an autonomous system
with an identity matrix as mass matrix. The following options can be
adjusted via :</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IFCN</span></code>: Specifies if the right hand side of the system dynamics
<span class="math notranslate nohighlight">\(\mb{f} (\mb{x},\mb{u},\mb{p},T)\)</span>
explicitly depends on time <span class="math notranslate nohighlight">\(t\)</span> (<code class="docutils literal notranslate"><span class="pre">IFCN</span></code> = <span class="math notranslate nohighlight">\(1\)</span>) or if
the problem is autonomous (<code class="docutils literal notranslate"><span class="pre">IFCN</span></code> = <span class="math notranslate nohighlight">\(0\)</span>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IDFX</span></code>: Specifies how the computation of the partial derivatives
<span class="math notranslate nohighlight">\(\frac{\partial^{} \mb{f}}{\partial t^{}}\)</span> and
<span class="math notranslate nohighlight">\(\frac{\partial^{2} H}{\partial x\partial t}\)</span> is carried out.
The partial derivatives are computed internally by finite differences
(<code class="docutils literal notranslate"><span class="pre">IDFX</span></code> = <span class="math notranslate nohighlight">\(0\)</span>) or are provided by the functions <code class="docutils literal notranslate"><span class="pre">dfdt</span></code> and <code class="docutils literal notranslate"><span class="pre">dHdxdt</span></code>
(<code class="docutils literal notranslate"><span class="pre">IDFX</span></code> = <span class="math notranslate nohighlight">\(1\)</span>) as described in <a class="reference internal" href="problem_formulation.html#sec-problemimplementation"><span class="std std-ref">Problem implementation</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IJAC</span></code>: Specifies how the computation of the Jacobians
<span class="math notranslate nohighlight">\(\frac{\partial^{} \mb{f}}{\partial \mb{x}^{}}\)</span>
and
<span class="math notranslate nohighlight">\((\frac{\partial^{} \mb{f}}{\partial \mb{x}^{}})^\mathsf{T}=\frac{\partial^{2} H}{\partial x\partial \lambda}\)</span>
is carried out for numerically solving the canonical equations. The
Jacobians are computed internally by finite differences
(<code class="docutils literal notranslate"><span class="pre">IJAC</span></code> = <span class="math notranslate nohighlight">\(0\)</span>) or are provided by the functions <code class="docutils literal notranslate"><span class="pre">dfdx</span></code> and <code class="docutils literal notranslate"><span class="pre">dfdxtrans</span></code>
(<code class="docutils literal notranslate"><span class="pre">IJAC</span></code> = <span class="math notranslate nohighlight">\(1\)</span>), also see <a class="reference internal" href="problem_formulation.html#sec-problemimplementation"><span class="std std-ref">Problem implementation</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">IMAS</span></code>: Gives information on the mass matrix <span class="math notranslate nohighlight">\(\mb{M}\)</span>, which
is either an identity matrix (<code class="docutils literal notranslate"><span class="pre">IMAS</span></code> = <span class="math notranslate nohighlight">\(0\)</span>) or is specified
by the function <code class="docutils literal notranslate"><span class="pre">Mfct</span></code> (<code class="docutils literal notranslate"><span class="pre">IMAS</span></code> = <span class="math notranslate nohighlight">\(1\)</span>). Note that the
adjoint dynamics requires the transposed mass matrix that has to be
provided by the function <code class="docutils literal notranslate"><span class="pre">Mtrans</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MLJAC</span></code>: Gives information on the banded structure of the Jacobian
<span class="math notranslate nohighlight">\(\frac{\partial^{} \mb{f}}{\partial \mb{x}^{}}\)</span>
and
<span class="math notranslate nohighlight">\((\frac{\partial^{} \mb{f}}{\partial \mb{x}^{}})^\mathsf{T}\)</span>,
respectively. The Jacobian is either a full matrix
(<code class="docutils literal notranslate"><span class="pre">MLJAC</span></code> = <span class="math notranslate nohighlight">\(N_x\)</span>) or is of banded structure. In the latter
case, the number of non-zero diagonals below the main diagonal are
specified by <span class="math notranslate nohighlight">\(0\leq\,\)</span><code class="docutils literal notranslate"><span class="pre">MLJAC</span></code><span class="math notranslate nohighlight">\(\,&lt;N_x\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MUJAC</span></code>: Specifies the number of non-zero diagonals above the main diagonal
of the Jacobian
<span class="math notranslate nohighlight">\(\frac{\partial^{} \mb{f}}{\partial \mb{x}^{}}\)</span>.
This flag needs not to to be defined if <code class="docutils literal notranslate"><span class="pre">MLJAC</span></code> = <span class="math notranslate nohighlight">\(N_x\)</span>.
Since the partial derivative of the right hand side of the adjoint
dynamics with respect to the adjoint state
<span class="math notranslate nohighlight">\(\mb{\lambda}\)</span> is given by
<span class="math notranslate nohighlight">\((\frac{\partial^{} \mb{f}}{\partial \mb{x}^{}})^\mathsf{T}\)</span>,
the meaning of the flags <code class="docutils literal notranslate"><span class="pre">MLJAC</span></code> and <code class="docutils literal notranslate"><span class="pre">MUJAC</span></code> switches in this
case.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MLMAS</span></code> and <code class="docutils literal notranslate"><span class="pre">MUMAS</span></code> : Both options have the same meaning as <code class="docutils literal notranslate"><span class="pre">MLJAC</span></code> and
<code class="docutils literal notranslate"><span class="pre">MUJAC</span></code>, but refer to the mass matrix <span class="math notranslate nohighlight">\(\mb{M}\)</span>.</p></li>
</ul>
<p>If a semi-implicit problem (option <code class="docutils literal notranslate"><span class="pre">IMAS</span></code> = <span class="math notranslate nohighlight">\(1\)</span>) with Mayer term (option
<code class="docutils literal notranslate"><span class="pre">TerminalCost</span></code> = <code class="docutils literal notranslate"><span class="pre">on</span></code>) is considered, the terminal conditions of the adjoint system
must be specified in a specific form. To provide
RODAS <a class="footnote-reference brackets" href="#footcite-hairer-book-1996-stiff" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-rodas-webpage-2018" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> the
proper terminal condition <span class="math notranslate nohighlight">\(\mb{\lambda}(T)\)</span>, the function <code class="docutils literal notranslate"><span class="pre">dVdx</span></code>
must be specified as follows</p>
<div class="math notranslate nohighlight">
\[\mb{\lambda}(T) = \underbrace{\left(\mb{M}^\mathsf{T}\right)^{-1}\bar{ V}_{\mb{x}}(\mb{x}(T), \mb{p}, T, \mb{\mu}_T, \mb{c}_T)}_{\texttt{dVdx}}\]</div>
<p>cf. Equation <a class="reference internal" href="#equation-eq-algopt-optcondlambda">(5)</a>.
In the case of a DAE system, the mass matrix is singular and therefore
only the elements of the mass matrix for the differential equations are
inverted. FOR an example of using RODAS and the respective options, take
a look at the MPC problem <code class="docutils literal notranslate"><span class="pre">Reactor_PDE</span></code> in the folder <code class="docutils literal notranslate"><span class="pre">&lt;grampc_root&gt;/examples</span></code>.</p>
</section>
</section>
<section id="line-search">
<span id="sec-algopt-linesearch"></span><h2>Line search<a class="headerlink" href="#line-search" title="Link to this heading">¶</a></h2>
<p>The projected gradient method as part of the GRAMPC algorithm
<a class="reference internal" href="#alg:AlgOpt:GrampcAlgorithm">Algorithm 1</a>)
requires the solution of the line search
problem <a class="footnote-reference brackets" href="#footcite-englert-oe-2019" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-linesearchproblem">
<span class="eqno">(6)<a class="headerlink" href="#equation-eq-algopt-linesearchproblem" title="Link to this equation">¶</a></span>\[\min_{\alpha} \bar{J} \left(
    \mb{\psi}_{\mb{u}} \left( \mb{u}^{i|j} - \alpha \mb{d}_{\mb{u}}^{i|j} \right),
    \mb{\psi}_{\mb{p}} \left( \mb{p}^{i|j} - \gamma_{\mb{p}} \alpha \mb{d}_{\mb{p}}^{i|j} \right),
    \psi_{T} \left( T^{i|j} - \gamma_{T} \alpha d_{T}^{i|j} \right);
    \mb{\bar \mu}, \mb{\bar c}, \mb{x}_0
\right)\,.\]</div>
<p>GRAMPC implements two efficient strategies to solve this problem in an
approximate manner. The following options apply to both line search
methods that are detailed below
(<a class="reference internal" href="#sec-algopt-linesearchadaptive"><span class="std std-ref">Adaptive line search</span></a> and
<a class="reference internal" href="#sec-algopt-linesearchexplicit"><span class="std std-ref">Explicit line search</span></a>):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchType</span></code>: This option selects either the adaptive line search strategy (value
<code class="docutils literal notranslate"><span class="pre">adaptive</span></code>) or the explicit approach (value <code class="docutils literal notranslate"><span class="pre">explicit1</span></code> or <code class="docutils literal notranslate"><span class="pre">explicit2</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchExpAutoFallback</span></code>: If this option is activated, the automatic fallback strategy is
used in the case that the explicit formulas result in negative step sizes.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchMax</span></code>: This option sets the maximum value <span class="math notranslate nohighlight">\(\alpha_{\max}\)</span> of the
step size <span class="math notranslate nohighlight">\(\alpha\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchMin</span></code>: This option sets the minimum value <span class="math notranslate nohighlight">\(\alpha_{\min}\)</span> of the
step size <span class="math notranslate nohighlight">\(\alpha\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchInit</span></code>: Indicates the initial value <span class="math notranslate nohighlight">\(\alpha_{\text{init}}&gt;0\)</span> for the
step size <span class="math notranslate nohighlight">\(\alpha\)</span>. If the adaptive line search is used, the
sample point <span class="math notranslate nohighlight">\(\alpha_2\)</span> is set
to<span class="math notranslate nohighlight">\(\alpha_2 = \alpha_{\text{init}}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OptimParamLineSearchFactor</span></code>: This option sets the adaptation factor
<span class="math notranslate nohighlight">\(\gamma_{\mb{p}}\)</span> that weights the update of the
parameter vector <span class="math notranslate nohighlight">\(\mb{p}\)</span> against the update of the
control <span class="math notranslate nohighlight">\(\mb{u}\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">OptimTimeLineSearchFactor</span></code>: This option sets the adaptation factor <span class="math notranslate nohighlight">\(\gamma_{T}\)</span> that
weights the update of the end time <span class="math notranslate nohighlight">\(T\)</span> against the update of
the control <span class="math notranslate nohighlight">\(\mb{u}\)</span>.</p></li>
</ul>
<section id="adaptive-line-search">
<span id="sec-algopt-linesearchadaptive"></span><h3>Adaptive line search<a class="headerlink" href="#adaptive-line-search" title="Link to this heading">¶</a></h3>
<p>An appropriate way to determine the step size is the adaptive line
search approach from <a class="footnote-reference brackets" href="#footcite-intech-graichenkaepernick2012" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a>,
where a polynomial approximation of the cost <span class="math notranslate nohighlight">\(\bar J\)</span> is used and an adaptation of
the search intervals is performed. More precisely, the cost functional
is evaluated at three sample points
<span class="math notranslate nohighlight">\(\alpha_1 &lt; \alpha_2 &lt; \alpha_3\)</span> with
<span class="math notranslate nohighlight">\(\alpha_2=\frac{1}{2}\left(\alpha_1+\alpha_3\right)\)</span>, which are
used to construct a quadratic polynomial of the cost according to</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-ls-adapt-approx">
<span class="eqno">(7)<a class="headerlink" href="#equation-eq-algopt-ls-adapt-approx" title="Link to this equation">¶</a></span>\[\begin{split}\bar{J}\left(
    \mb{\psi}_{\mb{u}} \left(\mb{u} ^{i|j} - \alpha \mb{d}_{\mb{u}} ^{i|j}\right),
    \mb{\psi}_{\mb{p}} \left(\mb{p} ^{i|j} - \gamma_{\mb{p}}\alpha \mb{d}_{\mb{p}} ^{i|j}\right),
    \psi_{T} \left(T ^{i|j} - \gamma_{T}\alpha   d_{T} ^{i|j} \right);
    \mb{\bar \mu}, \mb{\bar c}, \mb{x}_0
\right)\\
\approx \Phi(\alpha) = p_0+p_1\alpha +p_2\alpha_2\,.\end{split}\]</div>
<figure class="align-default" id="fig-algopt-ls-adapt">
<img alt="_images/ls_adapt.svg" src="_images/ls_adapt.svg" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Adaptation of line search interval.</span><a class="headerlink" href="#fig-algopt-ls-adapt" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p>Subsequently, a step size <span class="math notranslate nohighlight">\(\alpha^{j}\)</span> is computed by minimizing
the cost approximation <a class="reference internal" href="#equation-eq-algopt-ls-adapt-approx">(7)</a>. If
necessary, the interval <span class="math notranslate nohighlight">\([\alpha_1,\alpha_3]\)</span> is adapted for the
next gradient iteration in the following way</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-intervaladaptation">
<span class="eqno">(8)<a class="headerlink" href="#equation-eq-algopt-intervaladaptation" title="Link to this equation">¶</a></span>\[\begin{split}[\alpha_1,\alpha_3] &amp; \leftarrow
\begin{cases}
\hfill \kappa\,[\alpha_1,\alpha_3] &amp; \text{if} \ \alpha \geq
\alpha_3 - \varepsilon_{\alpha}(\alpha_3-\alpha_1) \ \text{and} \
\alpha_3 \leq \alpha_{\max} \ \text{and} \
|\Phi(\alpha_1)-\Phi(\alpha_3)| &gt;  \varepsilon_{\phi}
\\[1.5ex]
\hfill \frac{1}{\kappa} \,[\alpha_1,\alpha_3] &amp; \text{if} \ \alpha \leq
\alpha_1 + \varepsilon_{\alpha}(\alpha_3-\alpha_1) \ \text{and} \
\alpha_1 \geq \alpha_{\min}\ \text{and} \
|\Phi(\alpha_1)-\Phi(\alpha_3)| &gt; \varepsilon_{\phi}
\\[1.5ex]
\hfill[\alpha_1,\alpha_3] &amp; \text{otherwise}
\end{cases} \\[1.5ex]
%
\alpha_2 &amp; \leftarrow \frac{1}{2}\left(\alpha_1+\alpha_3\right)\end{split}\]</div>
<p>with the adaptation factor <span class="math notranslate nohighlight">\(\kappa &gt; 1\)</span>, the interval tolerance
<span class="math notranslate nohighlight">\(\varepsilon_{\alpha} \in (0,0.5)\)</span>, the absolute cost tolerance
<span class="math notranslate nohighlight">\({\varepsilon_{\phi}\in[0,\infty)}\)</span> for adapting the interval and
the interval bounds <span class="math notranslate nohighlight">\(\alpha_{\max}&gt;\alpha_{\min}&gt;0\)</span>.
The modification <a class="reference internal" href="#equation-eq-algopt-intervaladaptation">(8)</a> of
the line search interval tracks the minimum point <span class="math notranslate nohighlight">\(\alpha^{j}\)</span> of
the line search problem in the case when <span class="math notranslate nohighlight">\(\alpha^{j}\)</span> is either
outside of the interval <span class="math notranslate nohighlight">\([\alpha_1,\alpha_3]\)</span> or close to one of
the outer bounds <span class="math notranslate nohighlight">\(\alpha_1\)</span>, <span class="math notranslate nohighlight">\(\alpha_3\)</span>, as illustrated in
<a class="reference internal" href="#fig-algopt-ls-adapt"><span class="std std-numref">Fig. 2</span></a>. The adaptation factor
<span class="math notranslate nohighlight">\(\kappa\)</span> accounts for scaling as well as shifting of the interval
<span class="math notranslate nohighlight">\([\alpha_1,\alpha_3]\)</span> in the next gradient iteration, if
<span class="math notranslate nohighlight">\(\alpha^{j}\)</span> lies in the vicinity of the interval bounds
<span class="math notranslate nohighlight">\([\alpha_1,\alpha_3]\)</span> as specified by the interval tolerance
<span class="math notranslate nohighlight">\(\varepsilon_\alpha\)</span>. This adaptive strategy allows one to track
the minimum of the line search problem <a class="reference internal" href="#equation-eq-algopt-linesearchproblem">(6)</a> over
the gradient iterations <span class="math notranslate nohighlight">\(j\)</span> and MPC steps <span class="math notranslate nohighlight">\(k\)</span>, while
guaranteeing a fixed number of operations in view of a real-time MPC
implementation. The absolute tolerance <span class="math notranslate nohighlight">\(\varepsilon_{\phi}\)</span> of the
difference in the (scaled) costs at the interval bounds
<span class="math notranslate nohighlight">\(|\Phi(\alpha_1)-\Phi(\alpha_3)|\)</span> avoids oscillations of the
interval width in regions where the cost function <span class="math notranslate nohighlight">\(\bar{J}\)</span> is
almost constant.</p>
<p>The following options apply specifically to the adaptive line search
strategy:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchAdaptAbsTol</span></code>: This option sets the absolute tolerance <span class="math notranslate nohighlight">\(\varepsilon_{\phi}\)</span>
of the difference in costs at the interval bounds <span class="math notranslate nohighlight">\(\alpha_1\)</span>
and <span class="math notranslate nohighlight">\(\alpha_2\)</span>. If the difference in the (scaled) costs on
these bounds falls below <span class="math notranslate nohighlight">\(\varepsilon_{\phi}\)</span>, the adaption of
the interval is stopped in order to avoid oscillations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchAdaptFactor</span></code>: This option sets the adaptation factor <span class="math notranslate nohighlight">\(\kappa &gt; 1\)</span> in
<a class="reference internal" href="#equation-eq-algopt-intervaladaptation">(8)</a>
that determines how much the line search interval can be adapted from
one gradient iteration to the next.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchIntervalTol</span></code>: This option sets the interval tolerance
<span class="math notranslate nohighlight">\(\varepsilon_{\alpha} \in (0,0.5)\)</span> in
<a class="reference internal" href="#equation-eq-algopt-intervaladaptation">(8)</a>
that determines for which values of <span class="math notranslate nohighlight">\(\alpha\)</span> the adaption is
performed.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchIntervalFactor</span></code>: This option sets the interval factor <span class="math notranslate nohighlight">\(\beta \in (0,1)\)</span> that
specifies the interval bounds <span class="math notranslate nohighlight">\([\alpha_1,\alpha_3]\)</span> according
to <span class="math notranslate nohighlight">\(\alpha_1 = \alpha_2 (1 - \beta)\)</span> and
<span class="math notranslate nohighlight">\(\alpha_3 = \alpha_2 (1 + \beta)\)</span>, whereby the mid sample point
is initialized as <span class="math notranslate nohighlight">\(\alpha_2 = \alpha_\text{init}\)</span>.</p></li>
</ul>
</section>
<section id="explicit-line-search">
<span id="sec-algopt-linesearchexplicit"></span><h3>Explicit line search<a class="headerlink" href="#explicit-line-search" title="Link to this heading">¶</a></h3>
<p>An alternative way to determine the step size in order to further reduce
the computational effort for time-critical problems is the explicit line
search approach originally discussed in <a class="footnote-reference brackets" href="#footcite-barzilai1988" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a>
and adapted in <a class="footnote-reference brackets" href="#footcite-kaepernick2013" id="id16" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a> for the optimal
control case. The motivation is to minimize the difference between two
consecutive control updates <span class="math notranslate nohighlight">\(u_k^{i|j}(\tau)\)</span> and
<span class="math notranslate nohighlight">\(u_k^{i|j+1}(\tau)\)</span> in the unconstrained case and additionally
assuming the same step size <span class="math notranslate nohighlight">\(\alpha^{i|j}\)</span>, i.e.</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-ls-expl-prob">
<span class="eqno">(9)<a class="headerlink" href="#equation-eq-algopt-ls-expl-prob" title="Link to this equation">¶</a></span>\[\begin{split}\alpha^{i|j} &amp;= \underset{\alpha &gt; 0}{\arg\min} \; \Bigl\| {\mb{u}}^{i|j+1} - {\mb{u}}^{i|j} \Bigr\|^2_{L^2_m[0,T]} + \Bigl\| {\mb{p}}^{i|j+1} - {\mb{p}}^{i|j} \Bigr\|^2_2 + \Bigl| {T}^{i|j+1} - {T}^{i|j} \Bigr| \\
&amp;= \underset{\alpha &gt; 0}{\arg\min} \; \Bigl\| \underbrace{{\mb{u}}^{i|j} - {\mb{u}}^{j-1}}_{=:\Delta {\mb{u}}^{i|j}}- \alpha \underbrace{\left(\mb{d}^{i|j}_{\mb{u}}-\mb{d}^{j-1}_{\mb{u}}\right)}_{=:\Delta \mb{d}^{i|j}_{\mb{u}}} \Bigr\|^2_{L^2_m[0,T]} + \Bigl\| \underbrace{{\mb{p}}^{i|j} - {\mb{p}}^{j-1}}_{=:\Delta {\mb{p}}^{i|j}}- \gamma_{\mb{p}} \alpha \underbrace{\left(\mb{d}^{i|j}_{\mb{p}}-\mb{d}^{j-1}_{\mb{p}}\right)}_{=:\Delta \mb{d}^{i|j}_{\mb{p}}} \Bigr\|^2_2 \\
&amp; \qquad\qquad +\Bigl\| \underbrace{{T}^{i|j} - {T}^{j-1}}_{=:\Delta {T}^{i|j}}- \gamma_{T} \alpha \underbrace{\left({d}^{i|j}_{T}-{d}^{j-1}_{T}\right)}_{=:\Delta {d}^{i|j}_{T}} \Bigr\|^2_2\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(|| z ||^2_{L^2_m[0,T]} = \langle z,z \rangle :=\int_0^T z^\mathsf{T}(t) z(t) {\rm d}t\)</span>.</p>
<figure class="align-default" id="fig-algopt-ls-explicit">
<img alt="_images/ls_explicit.svg" src="_images/ls_explicit.svg" />
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Motivation for the explicit line search strategy.</span><a class="headerlink" href="#fig-algopt-ls-explicit" title="Link to this image">¶</a></p>
</figcaption>
</figure>
<p><a class="reference internal" href="#fig-algopt-ls-explicit"><span class="std std-numref">Fig. 3</span></a> illustrates the general idea
behind <a class="reference internal" href="#equation-eq-algopt-ls-expl-prob">(9)</a>. To solve
<a class="reference internal" href="#equation-eq-algopt-ls-expl-prob">(9)</a>, consider the
following function</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-q-alpha">
<span class="eqno">(10)<a class="headerlink" href="#equation-eq-algopt-q-alpha" title="Link to this equation">¶</a></span>\[\begin{split}q(\alpha) : &amp; =
\Bigl\| \Delta u_k^{j} - \alpha \Delta d_k^{j} \Bigr\|^2_{L^2_m[0,T]}
\\
&amp; = \int_{0}^{T} \left( \Delta u_k^{j} - \alpha \Delta d_k^{j} \right)^\mathsf{T}
\left( \Delta u_k^{j} - \alpha \Delta d_k^{j} \right) \, {\rm d}t
\\
&amp; = \int_{0}^{T} \left(\Delta u_k^{j}\right)^\mathsf{T}\Delta u_k^{j} \, {\rm d}t
+ \alpha^2 \int_{0}^{T} \left(\Delta d_k^{j}\right)^\mathsf{T}\Delta d_k^{j} \, {\rm d}t
- 2 \alpha \int_{0}^{T} \left(\Delta u_k^{j}\right)^\mathsf{T}\Delta d_k^{j} \, {\rm d}t.\end{split}\]</div>
<p>The minimum has to satisfy the stationarity condition</p>
<div class="math notranslate nohighlight">
\[\frac{\partial^{} q(\alpha)}{\partial \alpha^{}} =
2 \alpha \int_{0}^{T} \left(\Delta d_k^{j}\right)^\mathsf{T}\Delta d_k^{j} \, {\rm d}t
- 2 \int_{0}^{T} \left(\Delta u_k^{j} \right)^\mathsf{T}\Delta d_k^{j} \, {\rm d}t
= 0 .\]</div>
<p>A suitable step size <span class="math notranslate nohighlight">\(\alpha^{j}\)</span> then follows to</p>
<div class="math notranslate nohighlight">
\[\alpha^{j} =
\frac{\int_{0}^{T} \left( \Delta u_k^{j}\right)^\mathsf{T}\Delta d_k^{j} \, {\rm d}t}
{\int_{0}^{T} \left( \Delta d_k^{j}\right)^\mathsf{T}\Delta d_k^{j} \, {\rm d}t}
= \frac{\langle \Delta u_k^{j},\Delta d_k^{j}\rangle}
{\langle \Delta d_k^{j},\Delta d_k^{j} \rangle} \,.\]</div>
<p>Another way to compute an appropriate step size for the control update
can be achieved by reformulating
<a class="reference internal" href="#equation-eq-algopt-q-alpha">(10)</a> in the following way:</p>
<div class="math notranslate nohighlight">
\[\label{eq:AlgOpt:OptStepSizeQbar}
q(\alpha) =
\Bigl\| \Delta u_k^{j} - \alpha \Delta d_k^{j} \Bigr\|^2_{L^2_m[0,T]} =
\alpha^2 \Bigl\| \frac{1}{\alpha} \Delta u_k^{j} - \Delta d_k^{j} \Bigr\|^2_{L^2_m[0,T]}
=: \alpha^2 \bar q(\alpha).\]</div>
<p>In the subsequent, the new function <span class="math notranslate nohighlight">\(\bar q(\alpha)\)</span> is minimized
w.r.t. the step size leading to a similar solution</p>
<div class="math notranslate nohighlight">
\[\label{eq:AlgOpt:OptStepSize2}
\alpha^{j} = \frac{\langle\Delta u^{j}, \Delta u^{j} \rangle}
{\langle \Delta u^{j}, \Delta d_k^{j} \rangle} \,.\]</div>
<p>For the original problem <a class="reference internal" href="#equation-eq-algopt-ls-expl-prob">(9)</a>, the solution</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-ls-expl1">
<span class="eqno">(11)<a class="headerlink" href="#equation-eq-algopt-ls-expl1" title="Link to this equation">¶</a></span>\[\alpha^{i|j} =
\frac{\langle \Delta \mb{u}^{i|j},\Delta\mb{d}^{i|j}_{\mb{u}}\rangle
    +\gamma_{\mb{p}} \langle \Delta\mb{p}^{i|j},\Delta\mb{d}^{i|j}_{\mb{p}}\rangle
    +\gamma_{T} \Delta T^{i|j}\Delta{d}^{i|j}_{T}}
{\langle \Delta\mb{d}^{i|j}_{\mb{u}},\Delta \mb{d}^{i|j}_{\mb{u}} \rangle
    + \gamma_{\mb{p}}^2 \langle{\Delta\mb{d}^{i|j}_{\mb{p}}}^\mathsf{T}\Delta \mb{d}^{i|j}_{\mb{p}}\rangle
    + \gamma_{T}^2\big( \Delta {d}^{i|j}_{T}\big)^2}\]</div>
<div class="math notranslate nohighlight" id="equation-eq-algopt-ls-expl2">
<span class="eqno">(12)<a class="headerlink" href="#equation-eq-algopt-ls-expl2" title="Link to this equation">¶</a></span>\[\alpha^{i|j} =
\frac{\langle \Delta \mb{u}^{i|j}, \Delta\mb{u}^{i|j}\rangle
    + \gamma_{\mb{p}} \langle\Delta\mb{p}^{i|j}, \Delta\mb{p}^{i|j} \rangle
    + \gamma_{T} \big(\Delta T^{i|j}\big)^2}
{\langle \Delta\mb{u}^{i|j}, \Delta \mb{d}^{i|j}_{\mb{u}} \rangle
    + \gamma_{\mb{p}}^2 \langle\Delta\mb{p}^{i|j}, \Delta \mb{d}^{i|j}_{\mb{p}} \rangle
    + \gamma_{T}^2 \Delta {T}^{i|j} \Delta {d}^{i|j}_{T}}\]</div>
<p>follows.</p>
<p>In the GRAMPC implementation, both approaches <a class="reference internal" href="#equation-eq-algopt-ls-expl1">(11)</a> and
<a class="reference internal" href="#equation-eq-algopt-ls-expl2">(12)</a> are available.
In addition, the step size <span class="math notranslate nohighlight">\(\alpha^{j}\)</span> is bounded by the upper and
lower values <span class="math notranslate nohighlight">\(\alpha_{\max} &gt; \alpha_{\min} &gt; 0\)</span>. However, if the
originally computed step size <span class="math notranslate nohighlight">\(\alpha^{j}\)</span> is less than zero <a class="footnote-reference brackets" href="#id24" id="id17" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>,
either the initial step size <span class="math notranslate nohighlight">\(\alpha^{j} = \alpha_\text{init}\)</span> or
the automatic fallback strategy that is detailed in the next subsection
is used in order to achieve a valid step size. The fallback strategy is
set with the following option (only available for the explicit line
search strategies):</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">LineSearchExpAutoFallback</span></code>: If this option is activated, the automatic fallback strategy is
used in the case that the explicit formulas result in negative step sizes.</p></li>
</ul>
</section>
<section id="fallback-strategy-for-explicit-line-search">
<span id="sec-algopt-linesearchfallback"></span><h3>Fallback strategy for explicit line search<a class="headerlink" href="#fallback-strategy-for-explicit-line-search" title="Link to this heading">¶</a></h3>
<p>While the initial step size can be used as fallback solution if the
explicit step size computation yields negative values, it often requires
problem-specific tuning of <span class="math notranslate nohighlight">\(\alpha_\text{init}\)</span> for achieving
optimal performance. As alternative, GRAMPC implements an automatic
fallback strategy that is based on the idea of using at most 1% of the
control range defined by and . FOR this purpose, the maximum absolute
value
<span class="math notranslate nohighlight">\(\mb{d}^{i|j}_{\mb{u},\text{max}} = \| \mb{d}_{\mb{u}} ^{i|j}(t) \|_{L^\infty}\)</span>
of the search direction
<span class="math notranslate nohighlight">\(\mb{d}_{\mb{u}} ^{i|j}(t)\)</span> over the horizon is
determined. Subsequently, the step size</p>
<div class="math notranslate nohighlight">
\[    \alpha^{i|j} = \frac{1}{100} \cdot \min_{k\in\{1,\dots,N_{\mb{u}}\}}\left\lbrace
\frac{u_{\text{max},k}- u_{\text{min},k}} {d_{\mb{u},\text{max},k}^{i|j}}  \right\rbrace\]</div>
<p>follows as the minimal step size required to perform a step of 1% with
respect to the range of at least one control in at least one time step.
Additionally, the step size is limited to 10% of the maximum step size
<span class="math notranslate nohighlight">\(\alpha_{\max}\)</span>. Since this strategy requires reasonable limits
for the controls, it is only executed if <code class="docutils literal notranslate"><span class="pre">LineSearchExpAutoFallback</span></code> is activated and if these
limits are defined by the user. Furthermore, this strategy can only be
used if <code class="docutils literal notranslate"><span class="pre">OptimControl</span></code> is switched <code class="docutils literal notranslate"><span class="pre">on</span></code>. In all other case, the initial step size
<span class="math notranslate nohighlight">\(\alpha^{j}=\alpha_\text{init}\)</span> will be used as fallback solution.</p>
</section>
</section>
<section id="update-of-multipliers-and-penalties">
<span id="sec-algopt-updatemultpen"></span><h2>Update of multipliers and penalties<a class="headerlink" href="#update-of-multipliers-and-penalties" title="Link to this heading">¶</a></h2>
<p>GRAMPC handles general nonlinear constraints using an augmented
Lagrangian approach or, alternatively, using an external penalty method.
The key to the efficient solution of constrained problems using these
approaches are the updates of the multipliers in the outer loop for
<span class="math notranslate nohighlight">\(i = 1,\, \dots,\, i_\text{max}\)</span>.</p>
<section id="update-of-lagrangian-multipliers">
<span id="sec-algopt-updatemult"></span><h3>Update of Lagrangian multipliers<a class="headerlink" href="#update-of-lagrangian-multipliers" title="Link to this heading">¶</a></h3>
<p>The outer loop of the GRAMPC algorithm in:prf:ref:<cite>alg:AlgOpt:GrampcAlgorithm</cite>
maximizes the augmented Lagrangian function with respect to the
multipliers <span class="math notranslate nohighlight">\(\mb{\bar \mu}\)</span>. This update is carried out in
the direction of steepest ascent that is given by the constraint
residual. The penalty parameter is used as step size, as it is typically
done in augmented Lagrangian methods.</p>
<p>FOR an arbitrary equality constraint
<span class="math notranslate nohighlight">\(g^{i} = g(\mb{x}^{i}, \dots)\)</span> with multiplier
<span class="math notranslate nohighlight">\(\mu_g^{i}\)</span>, penalty <span class="math notranslate nohighlight">\(c_g^i\)</span>, and tolerance
<span class="math notranslate nohighlight">\(\varepsilon_g\)</span>, the update is defined by</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mu_g^{i+1} = \zeta_{g}(\mu_g^{i}, c_g^{i}, g^{i}, \varepsilon_g)
=
\begin{cases}
\mu^{i} + (1-\rho) c_g^{i} g^{i}
&amp; \text{if } \left|g^{i}\right| &gt;  \varepsilon_g
\, \land \,
\eta^{i} \leq \varepsilon_\text{rel,u}
\\
{\mu}_g^{i}
&amp; \text{else} \,.
\end{cases}\end{split}\]</div>
<p>The update is not performed if the constraint is satisfied within its
tolerance <span class="math notranslate nohighlight">\(\varepsilon\)</span> or if the inner minimization is not
sufficiently converged, which is checked by the maximum relative
gradient <span class="math notranslate nohighlight">\(\eta^i\)</span> (see <code class="xref math math-numref docutils literal notranslate"><span class="pre">eq:AlgOpt:RelGrad</span></code> for the definition) and the
threshold <span class="math notranslate nohighlight">\(\varepsilon_\text{rel,u}\)</span>. Similarly, for an inequality
constraint <span class="math notranslate nohighlight">\(h^{i} = h(\mb{x}^{i}, \dots)\)</span> with multiplier
<span class="math notranslate nohighlight">\(\mu_h^{i}\)</span>, penalty <span class="math notranslate nohighlight">\(c_h^{i}\)</span>, and tolerance
<span class="math notranslate nohighlight">\(\varepsilon_h\)</span>, the update is defined by</p>
<div class="math notranslate nohighlight">
\[\begin{split}\mu_h^{i+1} = \zeta_{h}(\mu_h^{i}, c_h^{i}, \bar h^{i}, \varepsilon_h)
=
\begin{cases}
\mu_h^{i} + (1-\rho) c_h^{i} \bar h^{i}
&amp; \text{if } \left(\bar h^{i} &gt; \varepsilon_h
\, \land \,
\eta^{i} \leq \varepsilon_\text{rel,u} \right)
\, \lor \,
\bar h^{i} &lt; 0
\\
\mu_h^{i}
&amp; \text{else} \,.
\end{cases}\end{split}\]</div>
<p>Similar update rules are used for the terminal equality and terminal
inequality constraints.</p>
<p>GRAMPC provides several means to increase the robustness of the
multiplier update, which may be required if few iterations
<span class="math notranslate nohighlight">\(j_\text{max}\)</span> are used for the suboptimal solution of the inner
minimization problem. The damping factor <span class="math notranslate nohighlight">\(\rho \in [0, 1)\)</span> can be
used to scale the step size of the steepest ascent and the tolerance
<span class="math notranslate nohighlight">\(\varepsilon_\text{rel,u}\)</span> can be used to skip the multiplier
update in case that the minimization is not sufficiently converged.
Furthermore, the multipliers are limited by lower and upper bounds
<span class="math notranslate nohighlight">\(\mu_g \in [-\mu_\text{max}, \mu_\text{max}]\)</span> for equalities and
<span class="math notranslate nohighlight">\(\mu_h \leq \mu_\text{max}\)</span> for inequalities, respectively, to
avoid unlimited growth. A status flag is set if one of the multipliers
reaches this bound and the user should check the problem formulation as
this case indicates an ill-posed or even infeasible optimization
problem.</p>
<p>The following options can be used to adjust the update of the Lagrangian
multipliers:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MultiplierMax</span></code>: Upper bound <span class="math notranslate nohighlight">\(\mu_\text{max}\)</span> and lower bound
<span class="math notranslate nohighlight">\(-\mu_\text{max}\)</span> for the Lagrangian multpliers.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MultiplierDampingFactor</span></code>:Damping factor <span class="math notranslate nohighlight">\(\rho \in [0,1)\)</span> for the multiplier update.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">AugLagUpdateGradientRelTol</span></code>: Threshold <span class="math notranslate nohighlight">\(\varepsilon_\text{rel,u}\)</span> for the maximum relative
gradient of the inner minimization problem.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ConstraintsAbsTol</span></code>: Thresholds
<span class="math notranslate nohighlight">\((\mb{\varepsilon_{\mb{g}}}, \mb{\varepsilon_{\mb{h}}}, \mb{\varepsilon_{\mb{g_T}}}, \mb{\varepsilon_{\mb{h_T}}}) \in \mathbb{R}^{N_{c}}\)</span>
for the equality, inequality, terminal equality, and terminal
inequality constraints.</p></li>
</ul>
</section>
<section id="update-of-penalty-parameters">
<span id="sec-algopt-updatepen"></span><h3>Update of penalty parameters<a class="headerlink" href="#update-of-penalty-parameters" title="Link to this heading">¶</a></h3>
<p>The penalty parameters <span class="math notranslate nohighlight">\(\mb{\bar c}\)</span> are adapted in each
outer iteration according to a heuristic rule that is motivated by the
LANCELOT package <a class="footnote-reference brackets" href="#footcite-conn2013" id="id18" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a><a class="footnote-reference brackets" href="#footcite-nocedal2006" id="id19" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a>. A carefully
tuned adaptation of the penalties can speed-up the convergence
significantly and is therefore highly recommended (also see
<a class="reference internal" href="#sec-algopt-estimpenmin"><span class="std std-ref">Estimation of minimal penalty parameter</span></a> and the tutorial in
<a class="reference internal" href="tutorials.html#sec-tut-pmsm"><span class="std std-ref">Model predictive control of a PMSM</span></a>). Note that the penalty parameters are
also updated if external penalties are used instead of the augmented
Lagrangian method, i.e. <code class="docutils literal notranslate"><span class="pre">ConstraintsHandling</span></code> is set to <code class="docutils literal notranslate"><span class="pre">extpen</span></code>. In order to keep the
penalty parameters at the initial value <code class="docutils literal notranslate"><span class="pre">PenaltyMin</span></code>, the options <code class="docutils literal notranslate"><span class="pre">PenaltyIncreaseFactor</span></code> and <code class="docutils literal notranslate"><span class="pre">PenaltyDecreaseFactor</span></code> can be set to
<span class="math notranslate nohighlight">\(1.0\)</span>, which basically deactivates the penalty update.</p>
<p>For an arbitrary equality constraint
<span class="math notranslate nohighlight">\(g^{i} = g(\mb{x}^{i}, \dots)\)</span> with penalty <span class="math notranslate nohighlight">\(c_g^i\)</span>
and tolerance <span class="math notranslate nohighlight">\(\varepsilon_g\)</span>, the update is defined by</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-updatepeng">
<span class="eqno">(13)<a class="headerlink" href="#equation-eq-algopt-updatepeng" title="Link to this equation">¶</a></span>\[\begin{split}c_g^{i+1} = \xi_g(c_g^{i}, g^{i}, g^{i-1}, \varepsilon_g)
=
\begin{cases}
\beta_{\mathrm{in}} \, c_g^{i}
&amp;\text{if } \left|g^{i}\right| \geq \gamma_{\mathrm{in}} \left|g^{i-1}\right|
\, \land \,
\left|g^{i}\right| &gt; \varepsilon_g
\, \land \,
\eta^{i} \leq \varepsilon_\text{rel,u}
\\
\beta_{\mathrm{de}} \, c_g^{i}
&amp;\text{else if } \left|g^{i}\right| \leq \gamma_{\mathrm{de}} \, \varepsilon_g
\\
c_g^{i}
&amp; \textrm{else} \,.
\end{cases}\end{split}\]</div>
<p>The penalty <span class="math notranslate nohighlight">\(c_g^{i}\)</span> is increased by the factor
<span class="math notranslate nohighlight">\(\beta_\text{in}&gt; 1\)</span> if the (sub-optimal) solution of the inner minimization problem
does not generate sufficient progress in the constraint, which is rated
by the factor <span class="math notranslate nohighlight">\(\gamma_\text{in} &gt; 0\)</span> and compared to the previous
iteration <span class="math notranslate nohighlight">\(i-1\)</span>. This update is skipped if the inner minimization
is not sufficiently converged, which is checked by the maximum relative
gradient <span class="math notranslate nohighlight">\(\eta^i\)</span> and the threshold
<span class="math notranslate nohighlight">\(\varepsilon_\text{rel,u}\)</span>. The penalty <span class="math notranslate nohighlight">\(c_g^{i}\)</span> is
decreased by the factor <span class="math notranslate nohighlight">\(\beta_\text{de} &lt; 1\)</span> if the constraint
<span class="math notranslate nohighlight">\(g^{i}\)</span> is sufficiently satisfied within its tolerance, whereby
currently the constant factor <span class="math notranslate nohighlight">\(\gamma_\text{de} = 0.1\)</span> is used.
The setting <span class="math notranslate nohighlight">\(\beta_\text{in} = \beta_\text{de} = 1\)</span> can be used to
keep the penalty constant, i.e., to deactivate the penalty adaptation.
Similarly, for an inequality constraint
<span class="math notranslate nohighlight">\(\bar h^{i} = \bar h(\mb{x}^{i}, \dots)\)</span> with penalty
<span class="math notranslate nohighlight">\(c_h^i\)</span> and tolerance <span class="math notranslate nohighlight">\(\varepsilon_h\)</span>, the update is defined
by</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-updatepenh">
<span class="eqno">(14)<a class="headerlink" href="#equation-eq-algopt-updatepenh" title="Link to this equation">¶</a></span>\[\begin{split}c_h^{i+1} = \xi_h(c_h^{i}, \bar h^{i}, \bar h^{i-1}, \varepsilon_h)
=
\begin{cases}
\beta_{\mathrm{in}} \, c_h^{i}
&amp;\text{if } \bar h^{i} \geq \gamma_{\mathrm{in}} \bar h^{i-1}
\, \land \,
\bar h^{i} &gt; \varepsilon_h
\, \land \,
\eta^{i} \leq \varepsilon_\text{rel,u}
\\
\beta_{\mathrm{de}} \, c_h^{i}
&amp; \text{else if } \bar h^{i} \leq \gamma_{\mathrm{de}} \, \varepsilon_h
\\
c_h^{i}
&amp; \textrm{else} \,.
\end{cases}\end{split}\]</div>
<p>Similar update rules are used for the terminal equality and inequality
constraints. In analogy to the multiplier update, the penalty parameters
are restricted to upper and lower bounds <span class="math notranslate nohighlight">\(c_\text{max} \gg
c_\text{min} &gt; 0\)</span> in order to avoid unlimited growth as well as
negligible values.</p>
<p>The following options can be used to adjust the update of the penalty
parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">PenaltyMax</span></code>: This option sets the upper bound <span class="math notranslate nohighlight">\(c_\text{max}\)</span> of the
penalty parameters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PenaltyMin</span></code>: This option sets the lower bound <span class="math notranslate nohighlight">\(c_\text{min}\)</span> of the
penalty parameters.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PenaltyIncreaseFactor</span></code>: This option sets the factor <span class="math notranslate nohighlight">\(\beta_\text{in}\)</span> by which
penalties are increased.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PenaltyDecreaseFactor</span></code>: This option sets the factor <span class="math notranslate nohighlight">\(\beta_\text{de}\)</span> by which
penalties are decreased.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">PenaltyIncreaseThreshold</span></code>: This option sets the factor <span class="math notranslate nohighlight">\(\gamma_\text{in}\)</span> that rates the
progress in the constraints between the last two iterates.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">AugLagUpdateGradientRelTol</span></code>: Threshold <span class="math notranslate nohighlight">\(\varepsilon_\text{rel,u}\)</span> for the maximum relative
gradient of the inner minimization problem.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ConstraintsAbsTol</span></code>: Thresholds
<span class="math notranslate nohighlight">\((\mb{\varepsilon_{\mb{g}}}, \mb{\varepsilon_{\mb{h}}}, \mb{\varepsilon_{\mb{g_T}}}, \mb{\varepsilon_{\mb{h_T}}}) \in \mathbb{R}^{N_{c}}\)</span>
for the equality, inequality, terminal equality, and terminal
inequality constraints.</p></li>
</ul>
</section>
<section id="estimation-of-minimal-penalty-parameter">
<span id="sec-algopt-estimpenmin"></span><h3>Estimation of minimal penalty parameter<a class="headerlink" href="#estimation-of-minimal-penalty-parameter" title="Link to this heading">¶</a></h3>
<p>In real-time or embedded MPC applications, where only a limited number
of iterations per step is computed, it is crucial that the penalty
parameter is not decreased below a certain threshold
<span class="math notranslate nohighlight">\(c_\text{min}\)</span>. This lower bound should be large enough that an
inactive constraint that becomes active is still sufficiently penalized
in the augmented Lagrangian cost functional. However, it should not be
chosen too high to prevent ill-conditioning. A suitable value of
<span class="math notranslate nohighlight">\(c_\text{min}\)</span> tailored to the given MPC problem therefore is of
importance to ensure a high performance of GRAMPC.</p>
<p>In order to support the user, GRAMPC offers the routine <code class="docutils literal notranslate"><span class="pre">grampc_estim_penmin</span></code> to compute a
problem-specific estimate of <span class="math notranslate nohighlight">\(c_\text{min}\)</span>. The basic idea behind
this estimation is to determine <span class="math notranslate nohighlight">\(c_\text{min}\)</span> such that the
actual costs <span class="math notranslate nohighlight">\(J\)</span> are in the same order of magnitude as the squared
constraints multiplied by <span class="math notranslate nohighlight">\(c_\text{min}\)</span>, see
equation <a class="reference internal" href="#equation-eq-algopt-auglag">(3)</a>. This approach
requires initial values for the states <span class="math notranslate nohighlight">\(\mb{x}\)</span>, controls
<span class="math notranslate nohighlight">\(\mb{u}\)</span>, and cost <span class="math notranslate nohighlight">\(J\)</span>. If the GRAMPC structure
includes only default values, i.e. zeros, (cold start) the estimation
function <code class="docutils literal notranslate"><span class="pre">grampc_estim_penmin</span></code> can be called with the argument <code class="docutils literal notranslate"><span class="pre">rungrampc=1</span></code> to perform one optimization
or MPC step, where the possible maximum numbers of gradient iterations <code class="docutils literal notranslate"><span class="pre">MaxGradIter</span></code>
and augmented Lagrangian iterations <code class="docutils literal notranslate"><span class="pre">MaxMultIter</span></code> are limited to 20. Afterwards, the
estimated value for <code class="docutils literal notranslate"><span class="pre">PenaltyMin</span></code> is set as detailed below and, if <code class="docutils literal notranslate"><span class="pre">rungrampc=1</span></code>, the initial
states <span class="math notranslate nohighlight">\(\mb{x}\)</span>, controls <span class="math notranslate nohighlight">\(\mb{u}\)</span> and costs
<span class="math notranslate nohighlight">\(J\)</span> are reset.</p>
<p>Based on the initial values, a first estimate of the minimal penalty
parameter is computed according to</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-c1">
<span class="eqno">(15)<a class="headerlink" href="#equation-eq-algopt-c1" title="Link to this equation">¶</a></span>\[\hat{c}_\text{min}^\text{I}
%= \frac{\tfrac{1}{2}\,|J|\,(N_{\vm{g}}+N_{\vm{h}})}
%{\|\vm g(\vm x(t), \vm u(t), \vm p, t)\|_{L_1}^2+\|\vm h(\vm x(t), \vm u(t), \vm p, t)\|_{L_1}^2 }
%+ \frac{\tfrac{1}{2}\,|J|\,(N_{\vm{g}_T}+N_{\vm{h}_T})} {\|\vm g_T(\vm x(T), \vm p, T)\|_{1}^2+\|\vm h_T(\vm x(T), \vm p, T)\|_{1}^2}
= \frac{2\,|J| %\,(N_{\vm{g}} + N_{\vm{h}} + N_{\vm{g}_T} + N_{\vm{h}_T})
}
{\|\mb{g}(\mb{x}(t), \mb{u}(t), \mb{p}, t)\|_{L_2}^2 + \|\mb{h}(\mb{x}(t), \mb{u}(t), \mb{p}, t)\|_{L_2}^2 + \|\mb{g}_T(\mb{x}(T), \mb{p}, T)\|_{2}^2 + \|\mb{h}_T(\mb{x}(T), \mb{p}, T)\|_{2}^2}\]</div>
<p>However, if the inequality constraints are initially inactive and are
far away from their bounds (i.e. large negative values are returned),
the estimate <span class="math notranslate nohighlight">\(\hat{c}_\text{min}^\text{I}\)</span> may be too small.</p>
<p>To deal with these cases, a second estimate for the minimal penalty
parameter</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-c2">
<span class="eqno">(16)<a class="headerlink" href="#equation-eq-algopt-c2" title="Link to this equation">¶</a></span>\[\hat{c}_\text{min}^\text{II}
%= \kappa \left(\frac{\tfrac{1}{2}\,|J|}
%{T \max\{\|\vm{\varepsilon}_{\vm{g}}\|_1,\,\|\vm{\varepsilon}_{\vm{h}}\|_1\}^2}
%+ \frac{\tfrac{1}{2}\,|J|}
%{\max\{\|\vm{\varepsilon}_{\vm{g}_T}\|_1,\,\|\vm{\varepsilon}_{\vm{h}_T}\|_1\}^2}\right)
= \frac{2\,|J|}
{
T \left(\|\mb{\varepsilon}_{\mb{g}}\|_2^2 +
\|\mb{\varepsilon}_{\mb{h}}\|_2^2\right) +
\|\mb{\varepsilon}_{\mb{g}_T}\|_2^2 +
\|\mb{\varepsilon}_{\mb{h}_T}\|_2^2}\]</div>
<p>is computed in the same spirit using the constraint tolerances (see <code class="docutils literal notranslate"><span class="pre">ConstraintsAbsTol</span></code>,
<span class="math notranslate nohighlight">\(\mb{\varepsilon}_{\mb{g}}\)</span>,
<span class="math notranslate nohighlight">\(\mb{\varepsilon}_{\mb{h}}\)</span>,
<span class="math notranslate nohighlight">\(\mb{\varepsilon}_{\mb{g}_T}\)</span> and
<span class="math notranslate nohighlight">\(\mb{\varepsilon}_{\mb{h}_T}\)</span>) instead of the
constraint values <a class="footnote-reference brackets" href="#id25" id="id20" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. Since the norms of the tolerances are summed,
more conservative values for <span class="math notranslate nohighlight">\(c_\text{min}\)</span> are estimated and
therefore instabilities can be avoided. Note that it is recommended to
scale all constraints so that they are in the same order of magnitude,
see e.g. the PMSM example in <a class="reference internal" href="tutorials.html#sec-tut-pmsm"><span class="std std-ref">Model predictive control of a PMSM</span></a>.</p>
<p>Finally, the minimal penalty parameter</p>
<div class="math notranslate nohighlight">
\[\hat{c}_\text{min} = \min\left\{
\max\left\{\hat{c}_\text{min}^\text{I} ,\,
\kappa \, \hat{c}_\text{min}^\text{II} \right\} ,\,
\frac{c_\text{max}}{500}\right\}\]</div>
<p>is chosen as the maximum of <a class="reference internal" href="#equation-eq-algopt-c1">(15)</a> and
<a class="reference internal" href="#equation-eq-algopt-c2">(16)</a> and additionally limited to
<span class="math notranslate nohighlight">\(0.2\%\)</span> of the maximum penalty parameter <span class="math notranslate nohighlight">\(c_\text{max}\)</span>.
This limitation ensures reasonable values even with very small
constraint tolerances. The relation factor <span class="math notranslate nohighlight">\(\kappa\)</span> has been
determined to <span class="math notranslate nohighlight">\(10^{-6}\)</span> on the basis of various example systems.
Please note that this estimation is intended to assist the user in
making an initial guess. Problem-specific tuning of <code class="docutils literal notranslate"><span class="pre">PenaltyMin</span></code> can lead to further
performance improvements and is therefore recommended. All MPC example
problems in <code class="docutils literal notranslate"><span class="pre">&lt;grampc_root&gt;/examples</span></code> contain an initial call of <code class="docutils literal notranslate"><span class="pre">grampc_estim_penmin</span></code> to estimate
<span class="math notranslate nohighlight">\(\hat{c}_\text{min}\)</span> and, as alternative, manually tuned values
that can further enhance the performance of GRAMPC for fixed numbers
of iterations.</p>
</section>
</section>
<section id="convergence-criterion">
<span id="sec-algopt-convcheck"></span><h2>Convergence criterion<a class="headerlink" href="#convergence-criterion" title="Link to this heading">¶</a></h2>
<p>While the usage of fixed iteration counts <span class="math notranslate nohighlight">\(i_\text{max}\)</span> and
<span class="math notranslate nohighlight">\(j_\text{max}\)</span> for the outer and inner loops is typical in
real-time MPC or MHE applications, GRAMPC also provides an optional
convergence check that is useful for solving optimal control or
parameter optimization problems, or if the computation time in MPC is of
minor importance.</p>
<p>The inner gradient loop in:prf:ref:<cite>alg:AlgOpt:GrampcAlgorithm</cite>
evaluates the maximum relative gradient</p>
<div class="math notranslate nohighlight">
\[ \label{eq:AlgOpt:RelGrad}
\eta^{i|j+1} =
\max\left\{
\frac{ \|\mb{u}^{i|j+1} - \mb{u}^{i|j}\|_{L_2} }
     { \|\mb{u}^{i|j+1}\|_{L_2} } \,,
\frac{ \left\| \mb{p}^{i|j+1} - \mb{p}^{i|j} \right\|_2 }
     { \left\| \mb{p}^{i|j+1} \right\|_2 } \,,
\frac{ |T^{i|j+1} - T^{i|j}| }
     { T^{i|j+1} }
\right\}\]</div>
<p>in each iteration <span class="math notranslate nohighlight">\(i|j\)</span> and terminates if</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-convgradient">
<span class="eqno">(17)<a class="headerlink" href="#equation-eq-algopt-convgradient" title="Link to this equation">¶</a></span>\[\eta^{i|j} \leq \varepsilon_\text{rel,c} \,.\]</div>
<p>Otherwise, the inner loop is continued until the maximum number of
iterations <span class="math notranslate nohighlight">\(j_\text{max}\)</span> is reached. The last value
<span class="math notranslate nohighlight">\(\eta^{i} = \eta^{i|j+1}\)</span> is returned to the outer loop and used
for the convergence check as well as for the update of multipliers and
penalties.</p>
<p>The augmented Lagrangian loop is terminated in iteration <span class="math notranslate nohighlight">\(i\)</span> if
the inner loop is converged, that is
<span class="math notranslate nohighlight">\(\eta^{i} \leq \varepsilon_\text{rel,c}\)</span>, and all constraints are
sufficiently satisfied, i.e.</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-convconstraints">
<span class="eqno">(18)<a class="headerlink" href="#equation-eq-algopt-convconstraints" title="Link to this equation">¶</a></span>\[\begin{split}\begin{bmatrix}
\thicknorm{\mb{g}^{i}(t)} \\ \mb{\max}\{\mb{0}, \mb{\bar h}^{i}(t)\}
\end{bmatrix}
\leq
\begin{bmatrix}
\mb{\varepsilon}_g \\ \mb{\varepsilon}_h
\end{bmatrix}
\, \forall t \in [0, T]
\quad \land \quad
\begin{bmatrix}
\thicknorm{\mb{g}_T^{i}} \\ \mb{\max}\{\mb{0}, \mb{\bar h}_T^{i}\}
\end{bmatrix}
\leq
\begin{bmatrix}
\mb{\varepsilon}_{g_T} \\ \mb{\varepsilon}_{h_T}
\end{bmatrix} \,,\end{split}\]</div>
<p>whereby the notation <span class="math notranslate nohighlight">\(\thicknorm{\cdot}\)</span> denotes the
component-wise absolute value. Otherwise, the outer loop is continued
until the maximum number of iterations <span class="math notranslate nohighlight">\(i_\text{max}\)</span> is reached.
The thresholds
<span class="math notranslate nohighlight">\(\mb{\varepsilon}_g, \mb{\varepsilon}_h, \mb{\varepsilon}_{g_T}, \mb{\varepsilon}_{h_T}\)</span>
are vector-valued in order to rate each constraint individually.</p>
<p>The following options can be used to adjust the convergence criterion:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ConvergenceCheck</span></code>: This option activates the convergence criterion. Otherwise, the
inner and outer loops always perform the maximum number of
iterations, see the options <code class="docutils literal notranslate"><span class="pre">MaxGradIter</span></code> and <code class="docutils literal notranslate"><span class="pre">MaxMultIter</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ConvergenceGradientRelTol</span></code>: This option sets the threshold <span class="math notranslate nohighlight">\(\varepsilon_\text{rel,c}\)</span> for
the maximum relative gradient of the inner minimization problem that
is used in the convergence criterion. Note that this threshold is
different from the one that is used in the update of multipliers and
penalties.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ConstraintsAbsTol</span></code>: Thresholds
<span class="math notranslate nohighlight">\((\mb{\varepsilon_{\mb{g}}}, \mb{\varepsilon_{\mb{h}}}, \mb{\varepsilon_{\mb{g_T}}}, \mb{\varepsilon_{\mb{h_T}}}) \in \mathbb{R}^{N_{c}}\)</span>
for the equality, inequality, terminal equality, and terminal
inequality constraints.</p></li>
</ul>
</section>
<section id="scaling">
<span id="sec-algopt-scaling"></span><h2>Scaling<a class="headerlink" href="#scaling" title="Link to this heading">¶</a></h2>
<p>Scaling is recommended for improving the numerical conditioning when the
states <span class="math notranslate nohighlight">\(\mb{x}\)</span> and the optimization variables
<span class="math notranslate nohighlight">\((\mb{u}, \mb{p}, T)\)</span> of the given optimization
problem differ in several orders of magnitude. Although GRAMPC allows
one to scale a specific problem automatically using the option
<code class="docutils literal notranslate"><span class="pre">ScaleProblem=1</span></code>, it should be noted that this typically increases the
computational load due to the additional multiplications in the
algorithm, cf. the tutorial on controlling a permanent magnet
synchronous machine in <a class="reference internal" href="tutorials.html#sec-tut-pmsm"><span class="std std-ref">Model predictive control of a PMSM</span></a>. This issue can
be avoided by directly formulating the scaled problem within the C file
template <code class="docutils literal notranslate"><span class="pre">probfct_TEMPLATE.c</span></code> included in the folder
<code class="docutils literal notranslate"><span class="pre">examples/TEMPLATE</span></code>, also see <a class="reference internal" href="problem_formulation.html#sec-problemimplementation"><span class="std std-ref">Problem implementation</span></a>.</p>
<p>The scaling in GRAMPC is performed according to</p>
<div class="math notranslate nohighlight" id="equation-eq-algopt-scaling">
<span class="eqno">(19)<a class="headerlink" href="#equation-eq-algopt-scaling" title="Link to this equation">¶</a></span>\[\begin{split}\bar{\mb{x}}(t) &amp; = (\mb{x}(t) - \mb{x}_{\text{offset}}) \,./\, \mb{x}_{\text{scale}} \\
\bar{\mb{u}}(t) &amp; = (\mb{u}(t) - \mb{u}_{\text{offset}}) \,./\, \mb{u}_{\text{scale}} \\
\bar{\mb{p}} &amp; = (\mb{p} - \mb{p}_{\text{offset}}) \,./\, \mb{p}_{\text{scale}} \\
\bar T &amp; = \frac{T - T_{\text{offset}}}{T_{\text{scale}}} \,,\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\mb{x}_{\text{offset}} \in \mathbb{R}^x\)</span>,
<span class="math notranslate nohighlight">\(\mb{u}_{\text{offset}} \in \mathbb{R}^u\)</span>,
<span class="math notranslate nohighlight">\(\mb{p}_{\text{offset}} \in \mathbb{R}^p\)</span> and
<span class="math notranslate nohighlight">\(\mb{T}_\text{offset} \in \mathbb{R}\)</span> denote offset values
and <span class="math notranslate nohighlight">\(\mb{x}_{\text{scale}} \in \mathbb{R}^x\)</span>,
<span class="math notranslate nohighlight">\(\mb{u}_{\text{scale}} \in \mathbb{R}^u\)</span>,
<span class="math notranslate nohighlight">\(\mb{p}_{\text{scale}} \in \mathbb{R}^p\)</span> and
<span class="math notranslate nohighlight">\(\mb{T}_\text{scale} \in \mathbb{R}\)</span> are scaling values.
The symbol <span class="math notranslate nohighlight">\(./\)</span> in <a class="reference internal" href="#equation-eq-algopt-scaling">(19)</a>
denotes element-wise division by the scaling vectors.</p>
<p>Furthermore, GRAMPC provides a scaling factor <span class="math notranslate nohighlight">\(J_\text{scale}\)</span>
for the cost functional as well as scaling factors
<span class="math notranslate nohighlight">\(\mb{c}_\text{scale} = [\mb{c}_{\text{scale},\mb{g}}, \mb{c}_{\text{scale},\mb{h}}, \mb{c}_{\text{scale},\mb{g}_T}, \mb{c}_{\text{scale},\mb{h}_T}] \in \mathbb{R}^{N_c}\)</span>
for the constraints. The scaling of the cost functional is relevant as
the constraints are adjoined to the cost functional by means of
Lagrangian multipliers and penalty parameters and the original cost
functional should be of the same order of magnitude as these additional
terms.</p>
<p>The following options can be used to adjust the scaling:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ScaleProblem</span></code>: Activates or deactivates scaling. Note that GRAMPC requires more
computation time if scaling is active.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">xScale</span></code>, <code class="docutils literal notranslate"><span class="pre">xOffset</span></code>: Scaling factors <span class="math notranslate nohighlight">\(\mb{x}_\text{scale}\)</span> and offsets
<span class="math notranslate nohighlight">\(\mb{x}_\text{offset}\)</span> for each state variable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">uScale</span></code>, <code class="docutils literal notranslate"><span class="pre">uOffset</span></code>: Scaling factors <span class="math notranslate nohighlight">\(\mb{u}_\text{scale}\)</span> and offsets
<span class="math notranslate nohighlight">\(\mb{u}_\text{offset}\)</span> for each control variable.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">pScale</span></code>, <code class="docutils literal notranslate"><span class="pre">pOffset</span></code>: Scaling factors <span class="math notranslate nohighlight">\(\mb{p}_\text{scale}\)</span> and offsets
<span class="math notranslate nohighlight">\(\mb{p}_\text{offset}\)</span> for each parameter.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TScale</span></code>, <code class="docutils literal notranslate"><span class="pre">TOffset</span></code>: Scaling factor <span class="math notranslate nohighlight">\(\mb{T}_\text{scale}\)</span> and offset
<span class="math notranslate nohighlight">\(\mb{T}_\text{offset}\)</span> for the horizon length.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">JScale</span></code>: Scaling factor <span class="math notranslate nohighlight">\(J_\text{scale}\)</span> for the cost functional.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cScale</span></code>: Scaling factors <span class="math notranslate nohighlight">\(\mb{c}_\text{scale}\)</span> for each state
constraint. The elements of the vector refer to the equality,
inequality, terminal equality and terminal inequality constraints.</p></li>
</ul>
</section>
<section id="control-shift">
<span id="sec-algopt-controlshift"></span><h2>Control shift<a class="headerlink" href="#control-shift" title="Link to this heading">¶</a></h2>
<p>The principle of optimality for an infinite horizon MPC problem
motivates to shift the control trajectory <span class="math notranslate nohighlight">\(\mb{u}(t)\)</span>,
<span class="math notranslate nohighlight">\(t\in[0,T]\)</span> from the previous MPC step <span class="math notranslate nohighlight">\(k-1\)</span> by the sampling
time <span class="math notranslate nohighlight">\(\Delta t\)</span> before the first GRAMPC iteration in the current
MPC step <span class="math notranslate nohighlight">\(k\)</span>,
cf. <a class="reference internal" href="#alg:AlgOpt:GrampcAlgorithm">Algorithm 1</a>.
The last time segment of the shifted trajectory is hold on the last
value of the trajectory. Shifting the control will lead to a faster
convergence behavior of the gradient algorithm for most MPC problems.</p>
<p>If the control shift is activated for a problem with free end time
<span class="math notranslate nohighlight">\(T\)</span>, GRAMPC assumes a shrinking horizon problem, because time
optimization is unusual in classical model predictive control. The
principle of optimality then motivates to subtract the sampling time
from the horizon <span class="math notranslate nohighlight">\(T\)</span> after each MPC step, which corresponds to a
control shift for the end time.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ShiftControl</span></code>: Activates or deactivates the shifting of the control trajectory and
the adaptation of <span class="math notranslate nohighlight">\(T\)</span> in case of a free end time, i.e., if <code class="docutils literal notranslate"><span class="pre">OptimTime</span></code> is
active.</p></li>
</ul>
</section>
<section id="status-flags">
<span id="sec-algopt-statusflags"></span><h2>Status flags<a class="headerlink" href="#status-flags" title="Link to this heading">¶</a></h2>
<p>Several status flags are set in the solution structure
<code class="docutils literal notranslate"><span class="pre">grampc.sol.status</span></code> during the execution of
<a class="reference internal" href="#alg:AlgOpt:GrampcAlgorithm">Algorithm 1</a>.
These flags can be printed as short messages by the function
<code class="docutils literal notranslate"><span class="pre">grampc_printstatus</span></code> for the levels error, warn, info and debug.</p>
<p>The following status flags are printed on the level
<code class="docutils literal notranslate"><span class="pre">STATUS_LEVEL_ERROR</span></code> and require immediate action:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_INTEGRATOR_INPUT_NOT_CONSISTENT</span></code>: This flag is set by the integrator <code class="docutils literal notranslate"><span class="pre">rodas</span></code> if the input values
are not consistent. See <a class="footnote-reference brackets" href="#footcite-rodas-webpage-2018" id="id21" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> for
further details.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_INTEGRATOR_MAXSTEPS</span></code>: This flag is set by the integrators <code class="docutils literal notranslate"><span class="pre">ruku45</span></code> or <code class="docutils literal notranslate"><span class="pre">rodas</span></code> if too
many steps are required.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_INTEGRATOR_STEPS_TOO_SMALL</span></code>: This flag is set by the integrator <code class="docutils literal notranslate"><span class="pre">rodas</span></code> if the step size
becomes too small.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_INTEGRATOR_MATRIX_IS_SINGULAR</span></code>: This flag is set by the integrator <code class="docutils literal notranslate"><span class="pre">rodas</span></code> if a singular Jacobian
<span class="math notranslate nohighlight">\(\frac{\partial \mb{f}}{\partial \mb{x}}\)</span> or
<span class="math notranslate nohighlight">\(\left(\frac{\partial \mb{f}}{\partial \mb{x}}\right)^\mathsf{T}\)</span>
is detected. See <a class="footnote-reference brackets" href="#footcite-rodas-webpage-2018" id="id22" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a> for further
details.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_INTEGRATOR_H_MIN</span></code>: This flag is set by the integrator <code class="docutils literal notranslate"><span class="pre">ruku45</span></code> if a smaller step
size than the minimal allowed value is required.</p></li>
</ul>
<p>The following flags are printed in addition to the previous ones on the
level <code class="docutils literal notranslate"><span class="pre">STATUS_LEVEL_WARN</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_MULTIPLIER_MAX</span></code>: This flag is set if one of the multipliers
<span class="math notranslate nohighlight">\(\mb{\bar \mu}\)</span> reaches the upper limit
<span class="math notranslate nohighlight">\(\mu_\text{max}\)</span> or the lower limit <span class="math notranslate nohighlight">\(-\mu_\text{max}\)</span>.
The situation may occur for example if the problem is infeasible or
ill-conditioned or if the penalty parameters are too high.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_PENALTY_MAX</span></code>: This flag is set if one of the penalty parameters
<span class="math notranslate nohighlight">\(\mb{\bar c}\)</span> reaches the upper limit
<span class="math notranslate nohighlight">\(c_\text{max}\)</span>. The situation may occur for example if the
problem is infeasible or ill-conditioned or if the penalty increase
factor <span class="math notranslate nohighlight">\(\beta_{\mathrm{in}}\)</span> is too high.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_INFEASIBLE</span></code>: This flag is set if the constraints are not satisfied and one run
of <a class="reference internal" href="#alg:AlgOpt:GrampcAlgorithm">Algorithm 1</a>
does not reduce the norm of the constraints. The situation may occur
in single runs, if few iterations <span class="math notranslate nohighlight">\(i_\text{max}\)</span> and
<span class="math notranslate nohighlight">\(j_\text{max}\)</span> are used for a suboptimal solution. However, if
the flag is set in multiple successive runs, it is a strong indicator
for an infeasible optimization problem.</p></li>
</ul>
<p>The following flags are printed in addition to the previous ones on the
level <code class="docutils literal notranslate"><span class="pre">STATUS_LEVEL_INFO</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_GRADIENT_CONVERGED</span></code>: This flag is set if the convergence check is activated and the
relative tolerance <span class="math notranslate nohighlight">\(\varepsilon_\text{rel,c}\)</span> is satisfied for
the controls <span class="math notranslate nohighlight">\(\mb{u}\)</span>, the parameters
<span class="math notranslate nohighlight">\(\mb{p}\)</span>, and the end time <span class="math notranslate nohighlight">\(T\)</span>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_CONSTRAINTS_CONVERGED</span></code>: This flag is set if the convergence check is activated and the
absolute tolerances
<span class="math notranslate nohighlight">\(\mb{\varepsilon}_g, \mb{\varepsilon}_h, \mb{\varepsilon}_{g_T}, \mb{\varepsilon}_{h_T}\)</span>
are satisfied for all constraints.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_LINESEARCH_INIT</span></code>: This flag is set if the gradient algorithm uses the initial step
size <span class="math notranslate nohighlight">\(\alpha_\text{init}\)</span> as fallback for the explicit line
search strategy in one iteration.</p></li>
</ul>
<p>The following flags are printed in addition to the previous ones on the
level <code class="docutils literal notranslate"><span class="pre">STATUS_LEVEL_DEBUG</span></code>:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_LINESEARCH_MAX</span></code>: This flag is set if the gradient algorithm uses the maximum step
size <span class="math notranslate nohighlight">\(\alpha_\text{max}\)</span> in one iteration.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_LINESEARCH_MIN</span></code>: This flag is set if the gradient algorithm uses the minimum step
size <span class="math notranslate nohighlight">\(\alpha_\text{min}\)</span> in one iteration.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">STATUS_MULTIPLIER_UPDATE</span></code>: This flag is set if the relative tolerance
<span class="math notranslate nohighlight">\(\varepsilon_\text{rel,u}\)</span> is satisfied for the controls
<span class="math notranslate nohighlight">\(\mb{u}\)</span>, the parameters <span class="math notranslate nohighlight">\(\mb{p}\)</span> and the
end time <span class="math notranslate nohighlight">\(T\)</span> and therefore the update of the multipliers
<span class="math notranslate nohighlight">\(\mb{\bar \mu}\)</span> and the penalty parameters
<span class="math notranslate nohighlight">\(\mb{\bar c}\)</span> is performed, cf. <a class="reference internal" href="#sec-algopt-updatemultpen"><span class="std std-ref">Update of multipliers and penalties</span></a>.</p></li>
</ul>
<div class="docutils container" id="id23">
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="footcite-englert-oe-2019" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id1">1</a>,<a role="doc-backlink" href="#id2">2</a>,<a role="doc-backlink" href="#id3">3</a>,<a role="doc-backlink" href="#id6">4</a>,<a role="doc-backlink" href="#id13">5</a>)</span>
<p>T. Englert, A. Völz, F. Mesmer, S. Rhein, and K. Graichen. A software framework for embedded nonlinear model predictive control using a gradient-based augmented Lagrangian approach (GRAMPC). <em>Optimization and Engineering</em>, 20(3):769–809, 2019. <a class="reference external" href="doi.org/10.1007/s11081-018-9417-2">doi.org/10.1007/s11081-018-9417-2</a>. <a class="reference external" href="https://doi.org/10.1007/s11081-018-9417-2">doi:10.1007/s11081-018-9417-2</a>.</p>
</aside>
<aside class="footnote brackets" id="footcite-intech-graichenkaepernick2012" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id4">1</a>,<a role="doc-backlink" href="#id14">2</a>)</span>
<p>K. Graichen and B. Käpernick. A real-time gradient method for nonlinear model predictive control. In T. Zheng, editor, <em>Frontiers of Model Predictive Control</em>, pages 9–28. InTech, 2012.</p>
</aside>
<aside class="footnote brackets" id="footcite-kaepernick2014" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id5">5</a><span class="fn-bracket">]</span></span>
<p>B. Käpernick and K. Graichen. The gradient based nonlinear model predictive control software GRAMPC. In <em>Proceedings of the European Control Conference (ECC)</em>, 1170–1175. Strasbourg (France), 2014.</p>
</aside>
<aside class="footnote brackets" id="footcite-hairer-book-1996-stiff" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id7">1</a>,<a role="doc-backlink" href="#id10">2</a>,<a role="doc-backlink" href="#id11">3</a>)</span>
<p>E. Hairer and G. Wanner. <em>Solving Ordinary Differential Equations: Stiff and Differential-Algebraic Problems</em>. Springer, Heidelberg, Germany, 1996.</p>
</aside>
<aside class="footnote brackets" id="footcite-rodas-webpage-2018" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id8">1</a>,<a role="doc-backlink" href="#id9">2</a>,<a role="doc-backlink" href="#id12">3</a>,<a role="doc-backlink" href="#id21">4</a>,<a role="doc-backlink" href="#id22">5</a>)</span>
<p>RODAS. Webpage. http://www.unige.ch/\texttt ~hairer/software.html, Accessed 01-December-2018.</p>
</aside>
<aside class="footnote brackets" id="footcite-barzilai1988" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">8</a><span class="fn-bracket">]</span></span>
<p>J. Barzilai and J. M. Borwein. Two-point step size gradient methods. <em>SIAM Journal on Numerical Analysis</em>, 8(1):141–148, 1988.</p>
</aside>
<aside class="footnote brackets" id="footcite-kaepernick2013" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id16">9</a><span class="fn-bracket">]</span></span>
<p>B. Käpernick and K. Graichen. Model predictive control of an overhead crane using constraint substitution. In <em>Proceedings of the American Control Conference (ACC)</em>, 3973–3978. 2013.</p>
</aside>
<aside class="footnote brackets" id="footcite-conn2013" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id18">10</a><span class="fn-bracket">]</span></span>
<p>A. R. Conn, G.I.M. Gould, and P. L. Toint. <em>LANCELOT: A Fortran Package for Large-Scale Nonlinear Optimization (Release A)</em>. Springer-Verlag, Berlin, Germany, 1992.</p>
</aside>
<aside class="footnote brackets" id="footcite-nocedal2006" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">11</a><span class="fn-bracket">]</span></span>
<p>J. Nocedal and S. Wright. <em>Numerical Optimization</em>. Springer Science &amp; Business Media, New York, USA, 2006.</p>
</aside>
</aside>
</div>
<p class="rubric">Footnotes</p>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">1</a><span class="fn-bracket">]</span></span>
<p>It can be shown in the one-dimensional case that the step size <span class="math notranslate nohighlight">\(\alpha\)</span> is negative if the cost function is locally non-convex.</p>
</aside>
<aside class="footnote brackets" id="id25" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id20">2</a><span class="fn-bracket">]</span></span>
<p>The integration behind the <span class="math notranslate nohighlight">\(L^2\)</span>-norm can be replaced by a multiplication by the horizon length <span class="math notranslate nohighlight">\(T\)</span>, as the constraint tolerances <span class="math notranslate nohighlight">\(\epsilon_g\)</span> and <span class="math notranslate nohighlight">\(\epsilon_h\)</span> are no functions of time.</p>
</aside>
</aside>
</section>
</section>


            <div class="clearer"></div>
          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
  <div>
    <h3><a href="index.html">Table of Contents</a></h3>
    <ul>
<li><a class="reference internal" href="#">Optimization algorithm and options</a><ul>
<li><a class="reference internal" href="#optimization-algorithm">Optimization algorithm</a><ul>
<li><a class="reference internal" href="#augmented-lagrangian-method">Augmented Lagrangian method</a></li>
<li><a class="reference internal" href="#projected-gradient-method">Projected gradient method</a></li>
<li><a class="reference internal" href="#algorithmic-structure">Algorithmic structure</a></li>
</ul>
</li>
<li><a class="reference internal" href="#numerical-integration">Numerical Integration</a><ul>
<li><a class="reference internal" href="#integration-of-cost-functional-and-explicit-odes">Integration of cost functional and explicit ODEs</a></li>
<li><a class="reference internal" href="#integration-of-semi-implicit-odes-and-daes-rodas">Integration of semi-implicit ODEs and DAEs (RODAS)</a></li>
</ul>
</li>
<li><a class="reference internal" href="#line-search">Line search</a><ul>
<li><a class="reference internal" href="#adaptive-line-search">Adaptive line search</a></li>
<li><a class="reference internal" href="#explicit-line-search">Explicit line search</a></li>
<li><a class="reference internal" href="#fallback-strategy-for-explicit-line-search">Fallback strategy for explicit line search</a></li>
</ul>
</li>
<li><a class="reference internal" href="#update-of-multipliers-and-penalties">Update of multipliers and penalties</a><ul>
<li><a class="reference internal" href="#update-of-lagrangian-multipliers">Update of Lagrangian multipliers</a></li>
<li><a class="reference internal" href="#update-of-penalty-parameters">Update of penalty parameters</a></li>
<li><a class="reference internal" href="#estimation-of-minimal-penalty-parameter">Estimation of minimal penalty parameter</a></li>
</ul>
</li>
<li><a class="reference internal" href="#convergence-criterion">Convergence criterion</a></li>
<li><a class="reference internal" href="#scaling">Scaling</a></li>
<li><a class="reference internal" href="#control-shift">Control shift</a></li>
<li><a class="reference internal" href="#status-flags">Status flags</a></li>
</ul>
</li>
</ul>

  </div>
  <div>
    <h4>Previous topic</h4>
    <p class="topless"><a href="problem_formulation.html"
                          title="previous chapter">Problem formulation and implementation</a></p>
  </div>
  <div>
    <h4>Next topic</h4>
    <p class="topless"><a href="usage.html"
                          title="next chapter">Usage of GRAMPC</a></p>
  </div>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="_sources/algorithm.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="Related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="prf-prf.html" title="Proof Index"
             >Proof</a> |</li>
        <li class="right" >
          <a href="usage.html" title="Usage of GRAMPC"
             >next</a> |</li>
        <li class="right" >
          <a href="problem_formulation.html" title="Problem formulation and implementation"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="index.html">grampc 2.3 documentation</a> &#187;</li>
        <li class="nav-item nav-item-this"><a href="">Optimization algorithm and options</a></li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
    &#169; Copyright 2024, Andreas Völz, Thore Wietzke.
      Created using <a href="https://www.sphinx-doc.org/">Sphinx</a> 7.4.0.
    </div>
  </body>
</html>